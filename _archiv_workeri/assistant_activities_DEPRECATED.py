import json
import logging
import os
from datetime import datetime
from typing import Dict, Any, Optional
import requests
from openai import OpenAI
from temporalio import activity

logger = logging.getLogger(__name__)

# Import centralizovan√©ho OpenAI clienta
try:
    import sys
    sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'backend'))
    from openai_client import get_openai_client, call_openai_chat, call_openai_image
    CENTRALIZED_CLIENT_AVAILABLE = True
    logger.info("‚úÖ Centralizovan√Ω OpenAI client √∫spƒõ≈°nƒõ importov√°n")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Centralizovan√Ω OpenAI client nen√≠ dostupn√Ω: {e}")
    CENTRALIZED_CLIENT_AVAILABLE = False



def get_api_key(service: str) -> str:
    """
    üö´ STRICT API KEY LOADING - ≈æ√°dn√© fallbacky
    Naƒçte API kl√≠ƒç pro danou slu≈æbu POUZE z backend API.
    
    Args:
        service: N√°zev slu≈æby (nap≈ô. "openai")
        
    Returns:
        API kl√≠ƒç
        
    Raises:
        Exception: Pokud API kl√≠ƒç nen√≠ nalezen - pipeline se zastav√≠
    """
    if not service:
        raise Exception("Service name pro API kl√≠ƒç nen√≠ specifikov√°n - workflow nelze spustit")
    
    try:
        # POUZE backend API - ≈æ√°dn√© fallbacky na environment variables
        backend_url = os.getenv("API_BASE_URL")
        if not backend_url:
            raise Exception("API_BASE_URL environment variable nen√≠ nastavena - workflow nelze spustit")
            
        response = requests.get(f"{backend_url}/api-keys/{service}", timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            api_key = data.get("api_key")
            if api_key and api_key != "Not found":
                logger.info(f"‚úÖ API kl√≠ƒç pro {service} naƒçten z backend API")
                return api_key
        
        # ≈Ω√°dn√Ω fallback - hard fail
        raise Exception(f"API kl√≠ƒç pro slu≈æbu {service} nen√≠ dostupn√Ω v backend API (status: {response.status_code}) - workflow nelze spustit")
        
    except requests.exceptions.RequestException as e:
        raise Exception(f"Nelze p≈ôipojit k backend API pro z√≠sk√°n√≠ API kl√≠ƒçe {service}: {e} - workflow nelze spustit")
    except Exception as e:
        raise Exception(f"Kritick√° chyba p≈ôi naƒç√≠t√°n√≠ API kl√≠ƒçe {service}: {e} - workflow nelze spustit")

@activity.defn
async def load_assistants_from_database(project_id: str) -> list:
    """
    Naƒçte seznam asistent≈Ø pro dan√Ω projekt z datab√°ze
    Pou≈æ√≠va SKUTEƒåN√â asistenty vytvo≈ôen√© u≈æivatelem v UI!
    """
    try:
        logger.info(f"üîÑ Naƒç√≠t√°m asistenty z datab√°ze pro projekt: {project_id}")
        
        if not project_id:
            error_msg = "‚ùå Project ID nen√≠ specifikov√°no - workflow nelze spustit bez ID projektu"
            logger.error(error_msg)
            raise Exception(error_msg)
        
        # üîó NAƒåTEN√ç Z DATAB√ÅZE p≈ôes backend API
        import requests
        import os
        
        # Sestaven√≠ URL pro backend API
        api_base_url = os.getenv('API_BASE_URL', 'http://localhost:8000')
        url = f"{api_base_url}/api/assistant/{project_id}"
        
        logger.info(f"üì° Vol√°m API: {url}")
        
        try:
            response = requests.get(url, timeout=30)
            
            # üö´ EXPLICIT HTTP 404 CHECK - okam≈æit√© selh√°n√≠ pro neexistuj√≠c√≠ projekt
            if response.status_code == 404:
                error_msg = f"‚ùå Projekt {project_id} neexistuje v datab√°zi - workflow nelze spustit"
                logger.error(error_msg)
                raise Exception(error_msg)
            
            response.raise_for_status()
            
            db_assistants = response.json()
            logger.info(f"‚úÖ Naƒçteno {len(db_assistants)} asistent≈Ø z datab√°ze")
            
            if not db_assistants:
                error_msg = f"‚ùå ≈Ω√°dn√≠ asistenti nenalezeni v datab√°zi pro projekt {project_id} - vytvo≈ôte asistenty p≈ôes UI"
                logger.error(error_msg)
                raise Exception(error_msg)
            
            # üö´ STRICT CONVERSION - ≈æ√°dn√© fallbacky v datab√°zov√Ωch datech
            workflow_assistants = []
            for i, db_assistant in enumerate(db_assistants):
                
                # Strict validace ka≈æd√©ho asistenta z datab√°ze
                function_key = db_assistant.get("functionKey")
                if not function_key:
                    raise Exception(f"‚ùå Asistent #{i+1} nem√° functionKey - datab√°ze je po≈°kozen√°, workflow nelze spustit")
                
                name = db_assistant.get("name")
                if not name:
                    raise Exception(f"‚ùå Asistent {function_key} nem√° n√°zev - datab√°ze je po≈°kozen√°, workflow nelze spustit")
                
                model_provider = db_assistant.get("model_provider")
                if not model_provider:
                    raise Exception(f"‚ùå Asistent {function_key} nem√° model_provider - mus√≠ b√Ωt nastaven v UI, workflow nelze spustit")
                
                model = db_assistant.get("model")
                if not model:
                    raise Exception(f"‚ùå Asistent {function_key} nem√° model - mus√≠ b√Ωt nastaven v UI, workflow nelze spustit")
                
                system_prompt = db_assistant.get("system_prompt")
                if not system_prompt:
                    raise Exception(f"‚ùå Asistent {function_key} nem√° system_prompt - mus√≠ b√Ωt nastaven v UI, workflow nelze spustit")
                
                order = db_assistant.get("order")
                if order is None:
                    raise Exception(f"‚ùå Asistent {function_key} nem√° order - mus√≠ b√Ωt nastaven v UI, workflow nelze spustit")
                
                temperature = db_assistant.get("temperature")
                if temperature is None:
                    raise Exception(f"‚ùå Asistent {function_key} nem√° temperature - mus√≠ b√Ωt nastavena v UI, workflow nelze spustit")
                
                max_tokens = db_assistant.get("max_tokens")
                if max_tokens is None:
                    raise Exception(f"‚ùå Asistent {function_key} nem√° max_tokens - mus√≠ b√Ωt nastaveno v UI, workflow nelze spustit")

                workflow_assistant = {
                    "id": function_key,
                    "name": name,
                    "function_key": function_key,
                    "slug": function_key,
                    "system_prompt": system_prompt,
                    "model_provider": model_provider,
                    "model": model,
                    "temperature": temperature,
                    "top_p": db_assistant.get("top_p"),  # Optional
                    "max_tokens": max_tokens,
                    "order": order,
                    "input_keys": ["topic"],  # Zjednodu≈°en√Ω input
                    "output_keys": ["output"]  # Zjednodu≈°en√Ω output
                }
                workflow_assistants.append(workflow_assistant)
            
            # Se≈ôazen√≠ podle order
            workflow_assistants.sort(key=lambda x: x["order"])
            
            logger.info(f"üéØ NAƒåTENO Z DATAB√ÅZE: {len(workflow_assistants)} asistent≈Ø")
            for assistant in workflow_assistants:
                logger.info(f"  {assistant['order']}. {assistant['name']} ({assistant['slug']})")
                
            return workflow_assistants
            
        except requests.exceptions.RequestException as e:
            error_msg = f"‚ùå Chyba p≈ôi p≈ôipojen√≠ k backend API: {e} - workflow nelze spustit bez p≈ô√≠stupu k datab√°zi"
            logger.error(error_msg)
            raise Exception(error_msg)
            
    except Exception as e:
        logger.error(f"‚ùå Kritick√° chyba p≈ôi naƒç√≠t√°n√≠ asistent≈Ø: {str(e)}")
        raise  # Re-raise the exception - ≈æ√°dn√© fallbacky!

# Fallback funkce odstranƒõna - pou≈æ√≠v√°me STRICT error handling
# Pokud datab√°ze sel≈æe, pipeline MUS√ç selhat!

@activity.defn
async def execute_assistant(args: dict) -> dict:
    """
    üö´ STRICT ASSISTANT EXECUTION - ≈æ√°dn√© fallbacky
    Spust√≠ konkr√©tn√≠ho asistenta s danou konfigurac√≠
    
    Args:
        args: Dict obsahuj√≠c√≠:
            - assistant_config: dict - konfigurace asistenta
            - topic: str - t√©ma pro zpracov√°n√≠
            - current_date: str - aktu√°ln√≠ datum (optional)
            - previous_outputs: dict - p≈ôedchoz√≠ v√Ωstupy (optional)
    """
    # STRICT INPUT VALIDATION
    if not args:
        raise Exception("‚ùå Args pro execute_assistant jsou pr√°zdn√© - pipeline nelze spustit")
        
    assistant_config = args.get("assistant_config")
    if not assistant_config:
        raise Exception("‚ùå Assistant_config chyb√≠ v args - pipeline nelze spustit")
    
    topic = args.get("topic")
    if topic is None:
        raise Exception("‚ùå Topic chyb√≠ v args - pipeline nelze spustit")
    if not topic.strip():
        logger.warning(f"‚ö†Ô∏è Topic je pr√°zdn√Ω pro {assistant_config.get('name', 'Unknown')} - pokraƒçuji s pr√°zdn√Ωm stringem")
        topic = ""
    
    current_date = args.get("current_date")  # Optional
    previous_outputs = args.get("previous_outputs", {})  # Optional
    
    # STRICT ASSISTANT CONFIG VALIDATION
    assistant_name = assistant_config.get("name")
    if not assistant_name:
        raise Exception("‚ùå Asistent nem√° name - konfigurace je neplatn√°, pipeline nelze spustit")
        
    function_key = assistant_config.get("function_key")
    if not function_key:
        raise Exception("‚ùå Asistent nem√° function_key - konfigurace je neplatn√°, pipeline nelze spustit")
    
    try:
        logger.info(f"ü§ñ ======== EXECUTE_ASSISTANT START ========")
        logger.info(f"ü§ñ Spou≈°t√≠m asistenta: {assistant_name}")
        logger.info(f"üìù Function Key: {function_key}")
        logger.info(f"üìÖ Current Date: {current_date if current_date else 'Not provided'}")
        logger.info(f"üìã Input Topic: {topic[:500]}...")
        logger.info(f"üìã Input Length: {len(topic)} chars")
        logger.info(f"üìã Previous Outputs Keys: {list(previous_outputs.keys()) if previous_outputs else 'None'}")
        
        # üö´ STRICT CONFIG VALIDATION - ≈æ√°dn√© fallbacky
        system_prompt = assistant_config.get("system_prompt")
        if not system_prompt:
            raise Exception(f"‚ùå Asistent {function_key} nem√° system_prompt - mus√≠ b√Ωt nastaven v UI, pipeline nelze spustit")
        
        model = assistant_config.get("model")
        if not model:
            raise Exception(f"‚ùå Asistent {function_key} nem√° model - mus√≠ b√Ωt nastaven v UI, pipeline nelze spustit")
        
        model_provider = assistant_config.get("model_provider")
        if not model_provider:
            raise Exception(f"‚ùå Asistent {function_key} nem√° model_provider - mus√≠ b√Ωt nastaven v UI, pipeline nelze spustit")
        
        temperature = assistant_config.get("temperature")
        if temperature is None:
            raise Exception(f"‚ùå Asistent {function_key} nem√° temperature - mus√≠ b√Ωt nastavena v UI, pipeline nelze spustit")
        
        max_tokens = assistant_config.get("max_tokens")
        if max_tokens is None:
            raise Exception(f"‚ùå Asistent {function_key} nem√° max_tokens - mus√≠ b√Ωt nastaveno v UI, pipeline nelze spustit")
        
        logger.info(f"ü§ñ ASSISTANT_CONFIG: model={model}, function_key={function_key}")
        logger.info(f"üìù PROMPT_LENGTH: {len(system_prompt)} chars, TOPIC_LENGTH: {len(topic)} chars")
        
        # üîç DEBUG: √öpln√Ω assistant_config
        logger.info(f"üîç DEBUG ASSISTANT_CONFIG: {json.dumps(assistant_config, indent=2, default=str)}")
        
        # Inicializace v√Ωstupn√≠ch promƒõnn√Ωch
        output = ""
        total_tokens = 0
        
        try:
            # Heartbeat p≈ôed dlouh√Ωm API vol√°n√≠m
            activity.heartbeat()
            
            # üé® ImageRendererAssistant pou≈æ√≠v√° DALL¬∑E API
            if function_key == "image_renderer_assistant":
                logger.info(f"üé® EXECUTING ImageRendererAssistant s DALL¬∑E API")
                
                # üö® OPRAVA: Parsov√°n√≠ JSON z MultimediaAssistant
                import re
                dalle_results = {"images": [], "model": "dall-e-3", "config": {}}
                
                try:
                    # Hled√°n√≠ JSON v markdown bloku nebo p≈ô√≠mo v topic
                    json_match = re.search(r'\[(.*?)\]', topic, re.DOTALL)
                    if json_match:
                        json_str = '[' + json_match.group(1) + ']'
                        multimedia_data = json.loads(json_str)
                        logger.info(f"üé® PARSED {len(multimedia_data)} image requests from MultimediaAssistant")
                        
                        api_key = get_api_key("openai")
                        client = OpenAI(api_key=api_key)
                        
                        # Generov√°n√≠ obr√°zku pro ka≈ædou image polo≈æku
                        for i, item in enumerate(multimedia_data):
                            if item.get('type') == 'image':
                                image_prompt = item.get('image_prompt', f"Professional image for: {topic}")
                                
                                # Limitace d√©lky promptu pro DALL¬∑E (max 1000 chars)
                                if len(image_prompt) > 1000:
                                    image_prompt = image_prompt[:997] + "..."
                                
                                logger.info(f"üé® GENERATING IMAGE {i+1}: {image_prompt[:80]}...")
                                
                                # DALL¬∑E 3 API vol√°n√≠
                                response = client.images.generate(
                                    model="dall-e-3",
                                    prompt=image_prompt,
                                    n=1,
                                    size="1024x1024",
                                    quality="standard",
                                    style="natural"
                                )
                                
                                # P≈ôid√°n√≠ do v√Ωsledk≈Ø
                                for img in response.data:
                                    dalle_results["images"].append({
                                        "url": img.url,
                                        "revised_prompt": img.revised_prompt if hasattr(img, 'revised_prompt') else image_prompt,
                                        "position": item.get('position', 'unknown'),
                                        "description": item.get('description', ''),
                                        "alt_text": item.get('alt_text', '')
                                    })
                        
                        logger.info(f"‚úÖ Generated {len(dalle_results['images'])} images from JSON")
                        
                    else:
                        raise Exception("No JSON found in topic")
                        
                except Exception as parse_error:
                    logger.warning(f"‚ö†Ô∏è JSON parsing failed, using fallback: {parse_error}")
                    # Fallback na p≈Øvodn√≠ logiku
                    image_prompt = f"Create a professional, high-quality image related to: {topic}. Make it suitable for SEO blog article, clean and engaging visual style."
                    
                    if len(image_prompt) > 1000:
                        image_prompt = image_prompt[:997] + "..."
                    
                    logger.info(f"üé® FALLBACK IMAGE_PROMPT: {image_prompt[:100]}...")
                    
                    api_key = get_api_key("openai")
                    client = OpenAI(api_key=api_key)
                    
                    # DALL¬∑E 3 API vol√°n√≠
                    response = client.images.generate(
                        model="dall-e-3",
                        prompt=image_prompt,
                        n=1,
                        size="1024x1024",
                        quality="standard",
                        style="natural"
                    )
                    
                    # Pro fallback mus√≠me zpracovat response
                    if not response.data:
                        raise Exception(f"‚ùå DALL-E API nevr√°tilo ≈æ√°dn√© obr√°zky pro {function_key} - pipeline selhal")
                    
                    for img in response.data:
                        if not img.url:
                            raise Exception(f"‚ùå DALL-E API vr√°tilo obr√°zek bez URL pro {function_key} - pipeline selhal")
                        
                        dalle_results["images"].append({
                            "url": img.url,
                            "revised_prompt": img.revised_prompt if hasattr(img, 'revised_prompt') else image_prompt,
                            "position": "main_article_image",
                            "description": f"AI generated image for: {topic}",
                            "alt_text": f"Professional image related to {topic}"
                        })
                
                # Heartbeat po DALL¬∑E vol√°n√≠
                activity.heartbeat()
                
                logger.info(f"‚úÖ DALL¬∑E API response √∫spƒõ≈°n√Ω!")
                logger.info(f"‚úÖ Generated {len(dalle_results['images'])} images")
                
                # Form√°tov√°n√≠ v√Ωstupu pro ImageRendererAssistant
                output = json.dumps({
                    "generated_images": dalle_results["images"],
                    "image_urls": [img["url"] for img in dalle_results["images"]],
                    "image_descriptions": [img.get("description", f"AI generated image for: {topic}") for img in dalle_results["images"]],
                    "alt_texts": [img.get("alt_text", f"Professional image related to {topic}") for img in dalle_results["images"]],
                    "positions": [img.get("position", "unknown") for img in dalle_results["images"]],
                    "prompts_used": [img.get("revised_prompt", "Unknown prompt") for img in dalle_results["images"]],
                    "model_used": dalle_results.get("model", "dall-e-3"),
                    "config": dalle_results.get("config", {})
                }, indent=2)
                
                total_tokens = 0  # DALL¬∑E nepou≈æ√≠v√° tokeny
                
            else:
                # ü§ñ Multi-provider LLM asistenti (OpenAI, Claude, Gemini)
                # model_provider, temperature, max_tokens u≈æ jsou validov√°ny v√Ω≈°e
                top_p = assistant_config.get("top_p")  # Optional pro Claude/Gemini
                
                logger.info(f"ü§ñ EXECUTING {model_provider.upper()} asistent: {assistant_name}")
                logger.info(f"üéØ Provider: {model_provider}, Model: {model}, Temperature: {temperature}")
                
                try:
                    # Import LLM factory
                    import sys
                    import os
                    sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'backend'))
                    
                    from llm_clients.factory import LLMClientFactory
                    
                    # Vytvo≈ôen√≠ clienta pro dan√Ω provider
                    llm_client = LLMClientFactory.create_client(model_provider)
                    
                    # P≈ô√≠prava user_message s aktu√°ln√≠m datem
                    user_message = topic
                    if current_date:
                        user_message = f"üìÖ Aktu√°ln√≠ datum: {current_date}\n\n{topic}"
                    
                    # üö® KRITICK√ù DEBUG PRO TOPIC CONTAMINATION
                    logger.info(f"üîç CONTAMINATION_DEBUG: ===== {function_key} =====")
                    logger.info(f"üîç RAW_TOPIC_INPUT: '{topic}'")
                    logger.info(f"üîç FINAL_USER_MESSAGE: '{user_message}'")
                    logger.info(f"üîç SYSTEM_PROMPT_START: '{system_prompt[:200]}...'")
                    
                    # Vol√°n√≠ chat completion s provider-specific parametry
                    # Heartbeat p≈ôed dlouh√Ωm LLM vol√°n√≠m (prevence CancelledError)
                    activity.heartbeat()
                    
                    if model_provider == "openai":
                        llm_result = await llm_client.chat_completion(
                            system_prompt=system_prompt,
                            user_message=user_message,
                            model=model,
                            temperature=temperature,
                            max_tokens=max_tokens,
                            top_p=top_p
                        )
                    elif model_provider == "claude":
                        # Claude nepodporuje top_p
                        llm_result = await llm_client.chat_completion(
                            system_prompt=system_prompt,
                            user_message=user_message,
                            model=model,
                            temperature=temperature,
                            max_tokens=max_tokens
                        )
                    elif model_provider == "gemini":
                        # Gemini m√° jin√© parametry
                        llm_result = await llm_client.chat_completion(
                            system_prompt=system_prompt,
                            user_message=user_message,
                            model=model,
                            temperature=temperature,
                            max_tokens=max_tokens
                        )
                    else:
                        raise Exception(f"Nepodporovan√Ω provider: {model_provider}")
                    
                    # Heartbeat po LLM vol√°n√≠
                    activity.heartbeat()
                    
                    logger.info(f"‚úÖ {model_provider.upper()} API response √∫spƒõ≈°n√Ω!")
                    logger.info(f"‚úÖ Model used: {llm_result['model']}")
                    logger.info(f"‚úÖ Provider: {llm_result['provider']}")
                    logger.info(f"‚úÖ Tokens used: {llm_result['usage']['total_tokens']}")
                    
                    # üîç DEBUG LLM RESULT STRUKTURA
                    logger.info(f"üîç LLM_RESULT KEYS: {list(llm_result.keys())}")
                    logger.info(f"üîç LLM_RESULT CONTENT: '{llm_result.get('content', 'MISSING_CONTENT')[:200]}...'")
                    
                    output = llm_result["content"]
                    total_tokens = llm_result["usage"]["total_tokens"]
                    
                except ImportError as e:
                    # üö´ ≈Ω√ÅDN√ù FALLBACK - pokud LLM Factory nen√≠ dostupn√Ω, pipeline sel≈æe
                    raise Exception(f"‚ùå LLM Factory nen√≠ dostupn√Ω - backend nen√≠ spr√°vnƒõ nakonfigurov√°n, pipeline nelze spustit: {e}")
                
                except Exception as e:
                    # üö´ ≈Ω√ÅDN√ù FALLBACK - pokud LLM client sel≈æe, pipeline sel≈æe
                    import traceback
                    logger.error(f"‚ùå {model_provider.upper()} API vol√°n√≠ selhalo: {str(e)}")
                    logger.error(f"‚ùå FULL TRACEBACK pro {assistant_name}:")
                    logger.error(traceback.format_exc())
                    logger.error(f"‚ùå INPUT DATA - function_key: {function_key}")
                    logger.error(f"‚ùå INPUT DATA - topic: {topic[:200]}...")
                    logger.error(f"‚ùå INPUT DATA - model_provider: {model_provider}")
                    logger.error(f"‚ùå INPUT DATA - model: {model}")
                    logger.error(f"‚ùå INPUT DATA - system_prompt: {system_prompt[:200]}...")
                    raise Exception(f"‚ùå LLM client pro {model_provider} selhal - pipeline nelze spustit: {e}")
                
            logger.info(f"‚úÖ Output d√©lka: {len(output)} znak≈Ø")
        
        except Exception as e:
            logger.error(f"‚ùå OpenAI API vol√°n√≠ selhalo!")
            logger.error(f"‚ùå Exception type: {type(e).__name__}")
            logger.error(f"‚ùå Exception message: {str(e)}")
            
            # Speci√°ln√≠ handling pro r≈Øzn√© typy chyb
            if "timeout" in str(e).lower():
                logger.error(f"‚è∞ TIMEOUT: OpenAI API vol√°n√≠ p≈ôekroƒçilo ƒçasov√Ω limit")
            elif "connection" in str(e).lower():
                logger.error(f"üåê CONNECTION: Probl√©m s p≈ôipojen√≠m k OpenAI API")
            elif "api_key" in str(e).lower() or "401" in str(e):
                logger.error(f"üîë AUTH: Probl√©m s API kl√≠ƒçem")
            elif "rate_limit" in str(e).lower() or "429" in str(e):
                logger.error(f"üö¶ RATE_LIMIT: P≈ôekroƒçen limit API vol√°n√≠")
            
            logger.error(f"‚ùå {assistant_name} selhal: {str(e)}")
            error_result = {
                "assistant_name": assistant_name,
                "function_key": function_key,
                "status": "failed",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
            raise Exception(f"Asistent {assistant_name} selhal: {str(e)}")
        
        # P≈ô√≠prava v√Ωsledku
        result = {
            "assistant_name": assistant_name,
            "function_key": function_key,
            "status": "completed",
            "output": output,
            "model_used": model,
            "tokens_used": total_tokens,
            "timestamp": datetime.now().isoformat()
        }
        
        logger.info(f"‚úÖ {assistant_name} dokonƒçen √∫spƒõ≈°nƒõ")
        logger.info(f"üìä Pou≈æito token≈Ø: {result['tokens_used']}")
        logger.info(f"üìÑ V√Ωstup d√©lka: {len(output)} znak≈Ø")
        
        # üö® KRITICK√ù DEBUG LOG - potvrzen√≠, ≈æe funkce dobƒõhla a≈æ na konec
        logger.info(f"üéØ RETURNING RESULT: {assistant_name} - funkce execute_assistant() dokonƒçena √∫spƒõ≈°nƒõ, vrac√≠m result")
        logger.info(f"üéØ RESULT KEYS: {list(result.keys())}")
        logger.info(f"üéØ RESULT STATUS: {result.get('status', 'UNKNOWN')}")
        
        return result
        
    except Exception as e:
        import traceback
        logger.error(f"‚ùå ======== EXECUTE_ASSISTANT FAILED ========")
        logger.error(f"‚ùå {assistant_name} selhal: {str(e)}")
        logger.error(f"‚ùå FINAL TRACEBACK pro {assistant_name}:")
        logger.error(traceback.format_exc())
        logger.error(f"‚ùå ASSISTANT CONFIG na ƒçase selh√°n√≠:")
        logger.error(f"‚ùå   function_key: {function_key}")
        logger.error(f"‚ùå   assistant_name: {assistant_name}")
        logger.error(f"‚ùå   topic_length: {len(topic) if topic else 0}")
        logger.error(f"‚ùå ======== EXECUTE_ASSISTANT END ========")
        error_result = {
            "assistant_name": assistant_name,
            "function_key": function_key,
            "status": "failed",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }
        raise Exception(f"Asistent {assistant_name} selhal v strict mode: {str(e)}")

@activity.defn
async def save_output_to_json(
    outputs: dict,
    topic: str,
    project_id: str
) -> dict:
    """
    Ulo≈æ√≠ fin√°ln√≠ v√Ωstupy do JSON souboru
    """
    try:
        logger.info(f"üíæ Ukl√°d√°m v√Ωstupy pro t√©ma: {topic}")
        
        # Vytvo≈ôen√≠ v√Ωsledn√©ho JSON objektu
        result = {
            "topic": topic,
            "project_id": project_id,
            "timestamp": datetime.now().isoformat(),
            "assistants": outputs,
            "status": "completed"
        }
        
        # Pro development jen logujeme, v produkci by se ukl√°dalo do datab√°ze/souboru
        logger.info(f"üìã Fin√°ln√≠ v√Ωstup p≈ôipraven ({len(str(result))} znak≈Ø)")
        logger.info(f"ü§ñ Poƒçet asistent≈Ø: {len(outputs)}")
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Chyba p≈ôi ukl√°d√°n√≠ v√Ωstup≈Ø: {str(e)}")
        raise 