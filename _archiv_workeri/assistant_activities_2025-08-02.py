import json
import logging
import os
from datetime import datetime
from typing import Dict, Any, Optional
import requests
from openai import OpenAI
from temporalio import activity

logger = logging.getLogger(__name__)

# Import centralizovanÃ©ho OpenAI clienta
try:
    import sys
    sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'backend'))
    from openai_client import get_openai_client, call_openai_chat, call_openai_image
    CENTRALIZED_CLIENT_AVAILABLE = True
    logger.info("âœ… CentralizovanÃ½ OpenAI client ÃºspÄ›Å¡nÄ› importovÃ¡n")
except ImportError as e:
    logger.warning(f"âš ï¸ CentralizovanÃ½ OpenAI client nenÃ­ dostupnÃ½: {e}")
    CENTRALIZED_CLIENT_AVAILABLE = False



def get_api_key(service: str) -> str:
    """
    ğŸš« STRICT API KEY LOADING - Å¾Ã¡dnÃ© fallbacky
    NaÄte API klÃ­Ä pro danou sluÅ¾bu POUZE z backend API.
    
    Args:
        service: NÃ¡zev sluÅ¾by (napÅ™. "openai")
        
    Returns:
        API klÃ­Ä
        
    Raises:
        Exception: Pokud API klÃ­Ä nenÃ­ nalezen - pipeline se zastavÃ­
    """
    if not service:
        raise Exception("Service name pro API klÃ­Ä nenÃ­ specifikovÃ¡n - workflow nelze spustit")
    
    try:
        # POUZE backend API - Å¾Ã¡dnÃ© fallbacky na environment variables
        backend_url = os.getenv("API_BASE_URL")
        if not backend_url:
            raise Exception("API_BASE_URL environment variable nenÃ­ nastavena - workflow nelze spustit")
            
        response = requests.get(f"{backend_url}/api-keys/{service}", timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            api_key = data.get("api_key")
            if api_key and api_key != "Not found":
                logger.info(f"âœ… API klÃ­Ä pro {service} naÄten z backend API")
                return api_key
        
        # Å½Ã¡dnÃ½ fallback - hard fail
        raise Exception(f"API klÃ­Ä pro sluÅ¾bu {service} nenÃ­ dostupnÃ½ v backend API (status: {response.status_code}) - workflow nelze spustit")
        
    except requests.exceptions.RequestException as e:
        raise Exception(f"Nelze pÅ™ipojit k backend API pro zÃ­skÃ¡nÃ­ API klÃ­Äe {service}: {e} - workflow nelze spustit")
    except Exception as e:
        raise Exception(f"KritickÃ¡ chyba pÅ™i naÄÃ­tÃ¡nÃ­ API klÃ­Äe {service}: {e} - workflow nelze spustit")

@activity.defn
async def load_assistants_from_database(project_id: str) -> list:
    """
    NaÄte seznam asistentÅ¯ pro danÃ½ projekt z databÃ¡ze
    PouÅ¾Ã­va SKUTEÄŒNÃ‰ asistenty vytvoÅ™enÃ© uÅ¾ivatelem v UI!
    """
    try:
        logger.info(f"ğŸ”„ NaÄÃ­tÃ¡m asistenty z databÃ¡ze pro projekt: {project_id}")
        
        if not project_id:
            error_msg = "âŒ Project ID nenÃ­ specifikovÃ¡no - workflow nelze spustit bez ID projektu"
            logger.error(error_msg)
            raise Exception(error_msg)
        
        # ğŸ”— NAÄŒTENÃ Z DATABÃZE pÅ™es backend API
        import requests
        import os
        
        # SestavenÃ­ URL pro backend API
        api_base_url = os.getenv('API_BASE_URL', 'http://localhost:8000')
        url = f"{api_base_url}/api/assistant/{project_id}"
        
        logger.info(f"ğŸ“¡ VolÃ¡m API: {url}")
        
        try:
            response = requests.get(url, timeout=30)
            
            # ğŸš« EXPLICIT HTTP 404 CHECK - okamÅ¾itÃ© selhÃ¡nÃ­ pro neexistujÃ­cÃ­ projekt
            if response.status_code == 404:
                error_msg = f"âŒ Projekt {project_id} neexistuje v databÃ¡zi - workflow nelze spustit"
                logger.error(error_msg)
                raise Exception(error_msg)
            
            response.raise_for_status()
            
            db_assistants = response.json()
            logger.info(f"âœ… NaÄteno {len(db_assistants)} asistentÅ¯ z databÃ¡ze")
            
            if not db_assistants:
                error_msg = f"âŒ Å½Ã¡dnÃ­ asistenti nenalezeni v databÃ¡zi pro projekt {project_id} - vytvoÅ™te asistenty pÅ™es UI"
                logger.error(error_msg)
                raise Exception(error_msg)
            
            # ğŸš« STRICT CONVERSION - Å¾Ã¡dnÃ© fallbacky v databÃ¡zovÃ½ch datech
            workflow_assistants = []
            for i, db_assistant in enumerate(db_assistants):
                
                # Strict validace kaÅ¾dÃ©ho asistenta z databÃ¡ze
                function_key = db_assistant.get("functionKey")
                if not function_key:
                    raise Exception(f"âŒ Asistent #{i+1} nemÃ¡ functionKey - databÃ¡ze je poÅ¡kozenÃ¡, workflow nelze spustit")
                
                name = db_assistant.get("name")
                if not name:
                    raise Exception(f"âŒ Asistent {function_key} nemÃ¡ nÃ¡zev - databÃ¡ze je poÅ¡kozenÃ¡, workflow nelze spustit")
                
                model_provider = db_assistant.get("model_provider")
                if not model_provider:
                    raise Exception(f"âŒ Asistent {function_key} nemÃ¡ model_provider - musÃ­ bÃ½t nastaven v UI, workflow nelze spustit")
                
                model = db_assistant.get("model")
                if not model:
                    raise Exception(f"âŒ Asistent {function_key} nemÃ¡ model - musÃ­ bÃ½t nastaven v UI, workflow nelze spustit")
                
                system_prompt = db_assistant.get("system_prompt")
                if not system_prompt:
                    raise Exception(f"âŒ Asistent {function_key} nemÃ¡ system_prompt - musÃ­ bÃ½t nastaven v UI, workflow nelze spustit")
                
                order = db_assistant.get("order")
                if order is None:
                    raise Exception(f"âŒ Asistent {function_key} nemÃ¡ order - musÃ­ bÃ½t nastaven v UI, workflow nelze spustit")
                
                temperature = db_assistant.get("temperature")
                if temperature is None:
                    raise Exception(f"âŒ Asistent {function_key} nemÃ¡ temperature - musÃ­ bÃ½t nastavena v UI, workflow nelze spustit")
                
                max_tokens = db_assistant.get("max_tokens")
                if max_tokens is None:
                    raise Exception(f"âŒ Asistent {function_key} nemÃ¡ max_tokens - musÃ­ bÃ½t nastaveno v UI, workflow nelze spustit")

                workflow_assistant = {
                    "id": function_key,
                    "name": name,
                    "function_key": function_key,
                    "slug": function_key,
                    "system_prompt": system_prompt,
                    "model_provider": model_provider,
                    "model": model,
                    "temperature": temperature,
                    "top_p": db_assistant.get("top_p"),  # Optional
                    "max_tokens": max_tokens,
                    "order": order,
                    "input_keys": ["topic"],  # ZjednoduÅ¡enÃ½ input
                    "output_keys": ["output"]  # ZjednoduÅ¡enÃ½ output
                }
                workflow_assistants.append(workflow_assistant)
            
            # SeÅ™azenÃ­ podle order
            workflow_assistants.sort(key=lambda x: x["order"])
            
            logger.info(f"ğŸ¯ NAÄŒTENO Z DATABÃZE: {len(workflow_assistants)} asistentÅ¯")
            for assistant in workflow_assistants:
                logger.info(f"  {assistant['order']}. {assistant['name']} ({assistant['slug']})")
                
            return workflow_assistants
            
        except requests.exceptions.RequestException as e:
            error_msg = f"âŒ Chyba pÅ™i pÅ™ipojenÃ­ k backend API: {e} - workflow nelze spustit bez pÅ™Ã­stupu k databÃ¡zi"
            logger.error(error_msg)
            raise Exception(error_msg)
            
    except Exception as e:
        logger.error(f"âŒ KritickÃ¡ chyba pÅ™i naÄÃ­tÃ¡nÃ­ asistentÅ¯: {str(e)}")
        raise  # Re-raise the exception - Å¾Ã¡dnÃ© fallbacky!

# Fallback funkce odstranÄ›na - pouÅ¾Ã­vÃ¡me STRICT error handling
# Pokud databÃ¡ze selÅ¾e, pipeline MUSÃ selhat!

@activity.defn
async def execute_assistant(args: dict) -> dict:
    """
    ğŸš« STRICT ASSISTANT EXECUTION - Å¾Ã¡dnÃ© fallbacky
    SpustÃ­ konkrÃ©tnÃ­ho asistenta s danou konfiguracÃ­
    
    Args:
        args: Dict obsahujÃ­cÃ­:
            - assistant_config: dict - konfigurace asistenta
            - topic: str - tÃ©ma pro zpracovÃ¡nÃ­
            - current_date: str - aktuÃ¡lnÃ­ datum (optional)
            - previous_outputs: dict - pÅ™edchozÃ­ vÃ½stupy (optional)
    """
    # STRICT INPUT VALIDATION
    if not args:
        raise Exception("âŒ Args pro execute_assistant jsou prÃ¡zdnÃ© - pipeline nelze spustit")
        
    assistant_config = args.get("assistant_config")
    if not assistant_config:
        raise Exception("âŒ Assistant_config chybÃ­ v args - pipeline nelze spustit")
    
    topic = args.get("topic")
    if topic is None:
        raise Exception("âŒ Topic chybÃ­ v args - pipeline nelze spustit")
    if not topic.strip():
        logger.warning(f"âš ï¸ Topic je prÃ¡zdnÃ½ pro {assistant_config.get('name', 'Unknown')} - pokraÄuji s prÃ¡zdnÃ½m stringem")
        topic = ""
    
    current_date = args.get("current_date")  # Optional
    previous_outputs = args.get("previous_outputs", {})  # Optional
    
    # STRICT ASSISTANT CONFIG VALIDATION
    assistant_name = assistant_config.get("name")
    if not assistant_name:
        raise Exception("âŒ Asistent nemÃ¡ name - konfigurace je neplatnÃ¡, pipeline nelze spustit")
        
    function_key = assistant_config.get("function_key")
    if not function_key:
        raise Exception("âŒ Asistent nemÃ¡ function_key - konfigurace je neplatnÃ¡, pipeline nelze spustit")
    
    try:
        logger.info(f"ğŸ¤– ======== EXECUTE_ASSISTANT START ========")
        logger.info(f"ğŸ¤– SpouÅ¡tÃ­m asistenta: {assistant_name}")
        logger.info(f"ğŸ“ Function Key: {function_key}")
        logger.info(f"ğŸ“… Current Date: {current_date if current_date else 'Not provided'}")
        logger.info(f"ğŸ“‹ Input Topic: {topic[:500]}...")
        logger.info(f"ğŸ“‹ Input Length: {len(topic)} chars")
        logger.info(f"ğŸ“‹ Previous Outputs Keys: {list(previous_outputs.keys()) if previous_outputs else 'None'}")
        
        # ğŸš« STRICT CONFIG VALIDATION - Å¾Ã¡dnÃ© fallbacky
        system_prompt = assistant_config.get("system_prompt")
        if not system_prompt:
            raise Exception(f"âŒ Asistent {function_key} nemÃ¡ system_prompt - musÃ­ bÃ½t nastaven v UI, pipeline nelze spustit")
        
        model = assistant_config.get("model")
        if not model:
            raise Exception(f"âŒ Asistent {function_key} nemÃ¡ model - musÃ­ bÃ½t nastaven v UI, pipeline nelze spustit")
        
        model_provider = assistant_config.get("model_provider")
        if not model_provider:
            raise Exception(f"âŒ Asistent {function_key} nemÃ¡ model_provider - musÃ­ bÃ½t nastaven v UI, pipeline nelze spustit")
        
        temperature = assistant_config.get("temperature")
        if temperature is None:
            raise Exception(f"âŒ Asistent {function_key} nemÃ¡ temperature - musÃ­ bÃ½t nastavena v UI, pipeline nelze spustit")
        
        max_tokens = assistant_config.get("max_tokens")
        if max_tokens is None:
            raise Exception(f"âŒ Asistent {function_key} nemÃ¡ max_tokens - musÃ­ bÃ½t nastaveno v UI, pipeline nelze spustit")
        
        logger.info(f"ğŸ¤– ASSISTANT_CONFIG: model={model}, function_key={function_key}")
        logger.info(f"ğŸ“ PROMPT_LENGTH: {len(system_prompt)} chars, TOPIC_LENGTH: {len(topic)} chars")
        
        # ğŸ” DEBUG: ÃšplnÃ½ assistant_config
        logger.info(f"ğŸ” DEBUG ASSISTANT_CONFIG: {json.dumps(assistant_config, indent=2, default=str)}")
        
        # Inicializace vÃ½stupnÃ­ch promÄ›nnÃ½ch
        output = ""
        total_tokens = 0
        
        try:
            # Heartbeat pÅ™ed dlouhÃ½m API volÃ¡nÃ­m
            activity.heartbeat()
            
            # ğŸ¨ ImageRendererAssistant pouÅ¾Ã­vÃ¡ DALLÂ·E API
            if function_key == "image_renderer_assistant":
                logger.info(f"ğŸ¨ EXECUTING ImageRendererAssistant s DALLÂ·E API")
                
                # ğŸš¨ OPRAVA: ParsovÃ¡nÃ­ JSON z MultimediaAssistant
                import re
                dalle_results = {"images": [], "model": "dall-e-3", "config": {}}
                
                try:
                    # HledÃ¡nÃ­ JSON v markdown bloku nebo pÅ™Ã­mo v topic
                    json_match = re.search(r'\[(.*?)\]', topic, re.DOTALL)
                    if json_match:
                        json_str = '[' + json_match.group(1) + ']'
                        multimedia_data = json.loads(json_str)
                        logger.info(f"ğŸ¨ PARSED {len(multimedia_data)} image requests from MultimediaAssistant")
                        
                        api_key = get_api_key("openai")
                        client = OpenAI(api_key=api_key)
                        
                        # GenerovÃ¡nÃ­ obrÃ¡zku pro kaÅ¾dou image poloÅ¾ku
                        for i, item in enumerate(multimedia_data):
                            if item.get('type') == 'image':
                                image_prompt = item.get('image_prompt', f"Professional image for: {topic}")
                                
                                # Limitace dÃ©lky promptu pro DALLÂ·E (max 1000 chars)
                                if len(image_prompt) > 1000:
                                    image_prompt = image_prompt[:997] + "..."
                                
                                logger.info(f"ğŸ¨ GENERATING IMAGE {i+1}: {image_prompt[:80]}...")
                                
                                # DALLÂ·E 3 API volÃ¡nÃ­
                                response = client.images.generate(
                                    model="dall-e-3",
                                    prompt=image_prompt,
                                    n=1,
                                    size="1024x1024",
                                    quality="standard",
                                    style="natural"
                                )
                                
                                # PÅ™idÃ¡nÃ­ do vÃ½sledkÅ¯
                                for img in response.data:
                                    dalle_results["images"].append({
                                        "url": img.url,
                                        "revised_prompt": img.revised_prompt if hasattr(img, 'revised_prompt') else image_prompt,
                                        "position": item.get('position', 'unknown'),
                                        "description": item.get('description', ''),
                                        "alt_text": item.get('alt_text', '')
                                    })
                        
                        logger.info(f"âœ… Generated {len(dalle_results['images'])} images from JSON")
                        
                    else:
                        raise Exception("No JSON found in topic")
                        
                except Exception as parse_error:
                    logger.warning(f"âš ï¸ JSON parsing failed, using fallback: {parse_error}")
                    # Fallback na pÅ¯vodnÃ­ logiku
                    image_prompt = f"Create a professional, high-quality image related to: {topic}. Make it suitable for SEO blog article, clean and engaging visual style."
                    
                    if len(image_prompt) > 1000:
                        image_prompt = image_prompt[:997] + "..."
                    
                    logger.info(f"ğŸ¨ FALLBACK IMAGE_PROMPT: {image_prompt[:100]}...")
                    
                    api_key = get_api_key("openai")
                    client = OpenAI(api_key=api_key)
                    
                    # DALLÂ·E 3 API volÃ¡nÃ­
                    response = client.images.generate(
                        model="dall-e-3",
                        prompt=image_prompt,
                        n=1,
                        size="1024x1024",
                        quality="standard",
                        style="natural"
                    )
                    
                    # Pro fallback musÃ­me zpracovat response
                    if not response.data:
                        raise Exception(f"âŒ DALL-E API nevrÃ¡tilo Å¾Ã¡dnÃ© obrÃ¡zky pro {function_key} - pipeline selhal")
                    
                    for img in response.data:
                        if not img.url:
                            raise Exception(f"âŒ DALL-E API vrÃ¡tilo obrÃ¡zek bez URL pro {function_key} - pipeline selhal")
                        
                        dalle_results["images"].append({
                            "url": img.url,
                            "revised_prompt": img.revised_prompt if hasattr(img, 'revised_prompt') else image_prompt,
                            "position": "main_article_image",
                            "description": f"AI generated image for: {topic}",
                            "alt_text": f"Professional image related to {topic}"
                        })
                
                # Heartbeat po DALLÂ·E volÃ¡nÃ­
                activity.heartbeat()
                
                logger.info(f"âœ… DALLÂ·E API response ÃºspÄ›Å¡nÃ½!")
                logger.info(f"âœ… Generated {len(dalle_results['images'])} images")
                
                # FormÃ¡tovÃ¡nÃ­ vÃ½stupu pro ImageRendererAssistant
                output = json.dumps({
                    "generated_images": dalle_results["images"],
                    "image_urls": [img["url"] for img in dalle_results["images"]],
                    "image_descriptions": [img.get("description", f"AI generated image for: {topic}") for img in dalle_results["images"]],
                    "alt_texts": [img.get("alt_text", f"Professional image related to {topic}") for img in dalle_results["images"]],
                    "positions": [img.get("position", "unknown") for img in dalle_results["images"]],
                    "prompts_used": [img.get("revised_prompt", "Unknown prompt") for img in dalle_results["images"]],
                    "model_used": dalle_results.get("model", "dall-e-3"),
                    "config": dalle_results.get("config", {})
                }, indent=2)
                
                total_tokens = 0  # DALLÂ·E nepouÅ¾Ã­vÃ¡ tokeny
                
            else:
                # ğŸ¤– Multi-provider LLM asistenti (OpenAI, Claude, Gemini)
                # model_provider, temperature, max_tokens uÅ¾ jsou validovÃ¡ny vÃ½Å¡e
                top_p = assistant_config.get("top_p")  # Optional pro Claude/Gemini
                
                logger.info(f"ğŸ¤– EXECUTING {model_provider.upper()} asistent: {assistant_name}")
                logger.info(f"ğŸ¯ Provider: {model_provider}, Model: {model}, Temperature: {temperature}")
                
                try:
                    # Import LLM factory
                    import sys
                    import os
                    sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'backend'))
                    
                    from llm_clients.factory import LLMClientFactory
                    
                    # VytvoÅ™enÃ­ clienta pro danÃ½ provider
                    llm_client = LLMClientFactory.create_client(model_provider)
                    
                    # PÅ™Ã­prava user_message s aktuÃ¡lnÃ­m datem
                    user_message = topic
                    if current_date:
                        user_message = f"ğŸ“… AktuÃ¡lnÃ­ datum: {current_date}\n\n{topic}"
                    
                    # ğŸš¨ KRITICKÃ DEBUG PRO TOPIC CONTAMINATION
                    logger.info(f"ğŸ” CONTAMINATION_DEBUG: ===== {function_key} =====")
                    logger.info(f"ğŸ” RAW_TOPIC_INPUT: '{topic}'")
                    logger.info(f"ğŸ” FINAL_USER_MESSAGE: '{user_message}'")
                    logger.info(f"ğŸ” SYSTEM_PROMPT_START: '{system_prompt[:200]}...'")
                    
                    # VolÃ¡nÃ­ chat completion s provider-specific parametry
                    # Heartbeat pÅ™ed dlouhÃ½m LLM volÃ¡nÃ­m (prevence CancelledError)
                    activity.heartbeat()
                    
                    if model_provider == "openai":
                        llm_result = await llm_client.chat_completion(
                            system_prompt=system_prompt,
                            user_message=user_message,
                            model=model,
                            temperature=temperature,
                            max_tokens=max_tokens,
                            top_p=top_p
                        )
                    elif model_provider == "claude":
                        # Claude nepodporuje top_p
                        llm_result = await llm_client.chat_completion(
                            system_prompt=system_prompt,
                            user_message=user_message,
                            model=model,
                            temperature=temperature,
                            max_tokens=max_tokens
                        )
                    elif model_provider == "gemini":
                        # Gemini mÃ¡ jinÃ© parametry
                        llm_result = await llm_client.chat_completion(
                            system_prompt=system_prompt,
                            user_message=user_message,
                            model=model,
                            temperature=temperature,
                            max_tokens=max_tokens
                        )
                    else:
                        raise Exception(f"NepodporovanÃ½ provider: {model_provider}")
                    
                    # Heartbeat po LLM volÃ¡nÃ­
                    activity.heartbeat()
                    
                    logger.info(f"âœ… {model_provider.upper()} API response ÃºspÄ›Å¡nÃ½!")
                    logger.info(f"âœ… Model used: {llm_result['model']}")
                    logger.info(f"âœ… Provider: {llm_result['provider']}")
                    logger.info(f"âœ… Tokens used: {llm_result['usage']['total_tokens']}")
                    
                    # ğŸ” DEBUG LLM RESULT STRUKTURA
                    logger.info(f"ğŸ” LLM_RESULT KEYS: {list(llm_result.keys())}")
                    logger.info(f"ğŸ” LLM_RESULT CONTENT: '{llm_result.get('content', 'MISSING_CONTENT')[:200]}...'")
                    
                    output = llm_result["content"]
                    total_tokens = llm_result["usage"]["total_tokens"]
                    
                except ImportError as e:
                    # ğŸš« Å½ÃDNÃ FALLBACK - pokud LLM Factory nenÃ­ dostupnÃ½, pipeline selÅ¾e
                    raise Exception(f"âŒ LLM Factory nenÃ­ dostupnÃ½ - backend nenÃ­ sprÃ¡vnÄ› nakonfigurovÃ¡n, pipeline nelze spustit: {e}")
                
                except Exception as e:
                    # ğŸš« Å½ÃDNÃ FALLBACK - pokud LLM client selÅ¾e, pipeline selÅ¾e
                    import traceback
                    logger.error(f"âŒ {model_provider.upper()} API volÃ¡nÃ­ selhalo: {str(e)}")
                    logger.error(f"âŒ FULL TRACEBACK pro {assistant_name}:")
                    logger.error(traceback.format_exc())
                    logger.error(f"âŒ INPUT DATA - function_key: {function_key}")
                    logger.error(f"âŒ INPUT DATA - topic: {topic[:200]}...")
                    logger.error(f"âŒ INPUT DATA - model_provider: {model_provider}")
                    logger.error(f"âŒ INPUT DATA - model: {model}")
                    logger.error(f"âŒ INPUT DATA - system_prompt: {system_prompt[:200]}...")
                    raise Exception(f"âŒ LLM client pro {model_provider} selhal - pipeline nelze spustit: {e}")
                
            logger.info(f"âœ… Output dÃ©lka: {len(output)} znakÅ¯")
        
        except Exception as e:
            logger.error(f"âŒ OpenAI API volÃ¡nÃ­ selhalo!")
            logger.error(f"âŒ Exception type: {type(e).__name__}")
            logger.error(f"âŒ Exception message: {str(e)}")
            
            # SpeciÃ¡lnÃ­ handling pro rÅ¯znÃ© typy chyb
            if "timeout" in str(e).lower():
                logger.error(f"â° TIMEOUT: OpenAI API volÃ¡nÃ­ pÅ™ekroÄilo ÄasovÃ½ limit")
            elif "connection" in str(e).lower():
                logger.error(f"ğŸŒ CONNECTION: ProblÃ©m s pÅ™ipojenÃ­m k OpenAI API")
            elif "api_key" in str(e).lower() or "401" in str(e):
                logger.error(f"ğŸ”‘ AUTH: ProblÃ©m s API klÃ­Äem")
            elif "rate_limit" in str(e).lower() or "429" in str(e):
                logger.error(f"ğŸš¦ RATE_LIMIT: PÅ™ekroÄen limit API volÃ¡nÃ­")
            
            logger.error(f"âŒ {assistant_name} selhal: {str(e)}")
            error_result = {
                "assistant_name": assistant_name,
                "function_key": function_key,
                "status": "failed",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
            raise Exception(f"Asistent {assistant_name} selhal: {str(e)}")
        
        # PÅ™Ã­prava vÃ½sledku
        result = {
            "assistant_name": assistant_name,
            "function_key": function_key,
            "status": "completed",
            "output": output,
            "model_used": model,
            "tokens_used": total_tokens,
            "timestamp": datetime.now().isoformat()
        }
        
        logger.info(f"âœ… {assistant_name} dokonÄen ÃºspÄ›Å¡nÄ›")
        logger.info(f"ğŸ“Š PouÅ¾ito tokenÅ¯: {result['tokens_used']}")
        logger.info(f"ğŸ“„ VÃ½stup dÃ©lka: {len(output)} znakÅ¯")
        
        # ğŸš¨ KRITICKÃ DEBUG LOG - potvrzenÃ­, Å¾e funkce dobÄ›hla aÅ¾ na konec
        logger.info(f"ğŸ¯ RETURNING RESULT: {assistant_name} - funkce execute_assistant() dokonÄena ÃºspÄ›Å¡nÄ›, vracÃ­m result")
        logger.info(f"ğŸ¯ RESULT KEYS: {list(result.keys())}")
        logger.info(f"ğŸ¯ RESULT STATUS: {result.get('status', 'UNKNOWN')}")
        
        return result
        
    except Exception as e:
        import traceback
        logger.error(f"âŒ ======== EXECUTE_ASSISTANT FAILED ========")
        logger.error(f"âŒ {assistant_name} selhal: {str(e)}")
        logger.error(f"âŒ FINAL TRACEBACK pro {assistant_name}:")
        logger.error(traceback.format_exc())
        logger.error(f"âŒ ASSISTANT CONFIG na Äase selhÃ¡nÃ­:")
        logger.error(f"âŒ   function_key: {function_key}")
        logger.error(f"âŒ   assistant_name: {assistant_name}")
        logger.error(f"âŒ   topic_length: {len(topic) if topic else 0}")
        logger.error(f"âŒ ======== EXECUTE_ASSISTANT END ========")
        error_result = {
            "assistant_name": assistant_name,
            "function_key": function_key,
            "status": "failed",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }
        raise Exception(f"Asistent {assistant_name} selhal v strict mode: {str(e)}")

@activity.defn
async def save_output_to_json(
    outputs: dict,
    topic: str,
    project_id: str
) -> dict:
    """
    UloÅ¾Ã­ finÃ¡lnÃ­ vÃ½stupy do JSON souboru
    """
    try:
        logger.info(f"ğŸ’¾ UklÃ¡dÃ¡m vÃ½stupy pro tÃ©ma: {topic}")
        
        # VytvoÅ™enÃ­ vÃ½slednÃ©ho JSON objektu
        result = {
            "topic": topic,
            "project_id": project_id,
            "timestamp": datetime.now().isoformat(),
            "assistants": outputs,
            "status": "completed"
        }
        
        # Pro development jen logujeme, v produkci by se uklÃ¡dalo do databÃ¡ze/souboru
        logger.info(f"ğŸ“‹ FinÃ¡lnÃ­ vÃ½stup pÅ™ipraven ({len(str(result))} znakÅ¯)")
        logger.info(f"ğŸ¤– PoÄet asistentÅ¯: {len(outputs)}")
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ Chyba pÅ™i uklÃ¡dÃ¡nÃ­ vÃ½stupÅ¯: {str(e)}")
        raise 