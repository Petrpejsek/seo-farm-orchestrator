#!/usr/bin/env python3
"""
üîç SIMPLE DEBUG WORKFLOWS
=========================

Zjednodu≈°en√© workflow pro testov√°n√≠ jednotliv√Ωch komponent:
- Single assistant test workflow
- Database test workflow  
- Image generation test workflow
- Publish script test workflow
- Connection test workflow

Ka≈æd√Ω workflow testuje jednu specifickou funkcionalitu izolovanƒõ.
"""

import os
import json
from datetime import timedelta
from typing import Dict, Any, Optional, List
from temporalio import workflow

# Import debugging n√°stroj≈Ø
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from helpers.db_logger import db_logger
from helpers.db_connection_audit import run_connection_audit
from helpers.db_activity_monitor import start_database_monitoring, get_database_health_report


@workflow.defn
class SingleAssistantTestWorkflow:
    """Test workflow pro jednotliv√©ho asistenta"""
    
    @workflow.run
    async def run(self, assistant_config: Dict[str, Any], test_input: str) -> Dict[str, Any]:
        """
        Testuje jedin√©ho asistenta izolovanƒõ
        
        Args:
            assistant_config: Konfigurace asistenta
            test_input: Testovac√≠ vstup
            
        Returns:
            V√Ωsledek testu asistenta
        """
        workflow_id = workflow.info().workflow_id
        run_id = workflow.info().run_id
        
        workflow.logger.info(f"üß™ SINGLE_ASSISTANT_TEST_START: {assistant_config.get('name', 'Unknown')}")
        
        test_result = {
            "workflow_id": workflow_id,
            "run_id": run_id,
            "assistant_name": assistant_config.get("name", "Unknown"),
            "function_key": assistant_config.get("function_key", "unknown"),
            "test_input": test_input,
            "timestamp": workflow.now().timestamp()
        }
        
        try:
            # Test z√°kladn√≠ activity pro asistenta
            workflow.logger.info(f"üîß Testing assistant: {assistant_config.get('name')}")
            
            assistant_result = await workflow.execute_activity(
                "execute_assistant",
                {
                    "assistant_config": assistant_config,
                    "topic": test_input,
                    "current_date": workflow.now().isoformat(),
                    "previous_outputs": {}
                },
                start_to_close_timeout=timedelta(minutes=5),
                schedule_to_close_timeout=timedelta(minutes=10),
                heartbeat_timeout=timedelta(minutes=1)
            )
            
            test_result.update({
                "success": True,
                "result": assistant_result,
                "duration": workflow.now().timestamp() - test_result["timestamp"]
            })
            
            workflow.logger.info(f"‚úÖ SINGLE_ASSISTANT_TEST_SUCCESS: {assistant_config.get('name')}")
            return test_result
            
        except Exception as e:
            test_result.update({
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__,
                "duration": workflow.now().timestamp() - test_result["timestamp"]
            })
            
            workflow.logger.error(f"‚ùå SINGLE_ASSISTANT_TEST_FAILED: {assistant_config.get('name')} - {e}")
            return test_result


@workflow.defn
class DatabaseTestWorkflow:
    """Test workflow pro datab√°zov√© operace"""
    
    @workflow.run
    async def run(self, test_config: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Testuje datab√°zov√© p≈ôipojen√≠ a operace
        
        Args:
            test_config: Konfigurace test≈Ø
            
        Returns:
            V√Ωsledky datab√°zov√Ωch test≈Ø
        """
        workflow_id = workflow.info().workflow_id
        run_id = workflow.info().run_id
        
        workflow.logger.info("üîç DATABASE_TEST_WORKFLOW_START")
        
        test_result = {
            "workflow_id": workflow_id,
            "run_id": run_id,
            "test_type": "database",
            "timestamp": workflow.now().timestamp(),
            "config": test_config or {}
        }
        
        try:
            # Test DB debug assistant
            workflow.logger.info("üîß Running database debug tests...")
            
            db_test_result = await workflow.execute_activity(
                "db_debug_assistant",
                test_config or {"comprehensive": True},
                start_to_close_timeout=timedelta(minutes=3),
                schedule_to_close_timeout=timedelta(minutes=5),
                heartbeat_timeout=timedelta(seconds=30)
            )
            
            test_result.update({
                "success": db_test_result.get("summary", {}).get("overall_success", False),
                "db_tests": db_test_result,
                "duration": workflow.now().timestamp() - test_result["timestamp"]
            })
            
            workflow.logger.info(f"‚úÖ DATABASE_TEST_WORKFLOW_SUCCESS: {db_test_result.get('summary', {}).get('success_count', 0)} tests passed")
            return test_result
            
        except Exception as e:
            test_result.update({
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__,
                "duration": workflow.now().timestamp() - test_result["timestamp"]
            })
            
            workflow.logger.error(f"‚ùå DATABASE_TEST_WORKFLOW_FAILED: {e}")
            return test_result


@workflow.defn
class ImageGenerationTestWorkflow:
    """Test workflow pro generov√°n√≠ obr√°zk≈Ø"""
    
    @workflow.run
    async def run(self, test_prompts: list = None) -> Dict[str, Any]:
        """
        Testuje generov√°n√≠ obr√°zk≈Ø izolovanƒõ
        
        Args:
            test_prompts: Seznam test prompt≈Ø
            
        Returns:
            V√Ωsledky test≈Ø generov√°n√≠ obr√°zk≈Ø
        """
        workflow_id = workflow.info().workflow_id
        run_id = workflow.info().run_id
        
        workflow.logger.info("üé® IMAGE_GENERATION_TEST_WORKFLOW_START")
        
        # Default test prompts
        if not test_prompts:
            test_prompts = [
                "A simple red circle on white background",
                "Blue square with text 'TEST'",
                "Green triangle, minimalist style"
            ]
        
        test_result = {
            "workflow_id": workflow_id,
            "run_id": run_id,
            "test_type": "image_generation",
            "timestamp": workflow.now().timestamp(),
            "test_prompts": test_prompts,
            "results": []
        }
        
        try:
            # Naƒçten√≠ ImageRenderer konfigurace
            workflow.logger.info("üìã Loading ImageRenderer configuration...")
            
            assistants_config = await workflow.execute_activity(
                "load_assistants_from_database",
                "default_project_id",  # TODO: Use actual project ID
                schedule_to_close_timeout=timedelta(seconds=30),
                heartbeat_timeout=timedelta(seconds=10)
            )
            
            # Naj√≠t ImageRenderer
            assistants = assistants_config.get("assistants", [])
            image_renderer = None
            for assistant in assistants:
                if assistant.get("function_key") == "image_renderer_assistant":
                    image_renderer = assistant
                    break
            
            if not image_renderer:
                raise Exception("ImageRenderer assistant not found in database")
            
            # Test generov√°n√≠ pro ka≈æd√Ω prompt
            for i, prompt in enumerate(test_prompts):
                workflow.logger.info(f"üé® Testing image generation {i+1}/{len(test_prompts)}: {prompt[:50]}...")
                
                try:
                    # Vytvo≈ô multimedia n√°vrhy pro ImageRenderer
                    multimedia_input = {
                        "suggestions": [
                            {
                                "type": "image",
                                "prompt": prompt,
                                "style": "test image",
                                "priority": "high"
                            }
                        ]
                    }
                    
                    image_result = await workflow.execute_activity(
                        "execute_assistant",
                        {
                            "assistant_config": image_renderer,
                            "topic": multimedia_input,
                            "current_date": workflow.now().isoformat(),
                            "previous_outputs": {}
                        },
                        start_to_close_timeout=timedelta(minutes=3),
                        schedule_to_close_timeout=timedelta(minutes=5),
                        heartbeat_timeout=timedelta(seconds=30)
                    )
                    
                    test_result["results"].append({
                        "prompt": prompt,
                        "success": True,
                        "result": image_result,
                        "images_generated": len(image_result.get("output", {}).get("images", [])) if image_result.get("output") else 0
                    })
                    
                except Exception as e:
                    test_result["results"].append({
                        "prompt": prompt,
                        "success": False,
                        "error": str(e),
                        "error_type": type(e).__name__
                    })
                    workflow.logger.error(f"‚ùå Image generation failed for prompt {i+1}: {e}")
            
            # Celkov√© vyhodnocen√≠
            successful_tests = sum(1 for result in test_result["results"] if result["success"])
            test_result.update({
                "success": successful_tests > 0,
                "successful_tests": successful_tests,
                "total_tests": len(test_prompts),
                "success_rate": successful_tests / len(test_prompts),
                "duration": workflow.now().timestamp() - test_result["timestamp"]
            })
            
            workflow.logger.info(f"‚úÖ IMAGE_GENERATION_TEST_WORKFLOW_COMPLETE: {successful_tests}/{len(test_prompts)} tests passed")
            return test_result
            
        except Exception as e:
            test_result.update({
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__,
                "duration": workflow.now().timestamp() - test_result["timestamp"]
            })
            
            workflow.logger.error(f"‚ùå IMAGE_GENERATION_TEST_WORKFLOW_FAILED: {e}")
            return test_result


@workflow.defn
class PublishScriptTestWorkflow:
    """Test workflow pro publish script"""
    
    @workflow.run
    async def run(self, mock_pipeline_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Testuje publish script izolovanƒõ
        
        Args:
            mock_pipeline_data: Mock data z pipeline
            
        Returns:
            V√Ωsledky testu publish scriptu
        """
        workflow_id = workflow.info().workflow_id
        run_id = workflow.info().run_id
        
        workflow.logger.info("üöÄ PUBLISH_SCRIPT_TEST_WORKFLOW_START")
        
        # Default mock data
        if not mock_pipeline_data:
            mock_pipeline_data = {
                "brief_assistant_output": "Test brief about testing",
                "research_assistant_output": "Test research data",
                "fact_validator_assistant_output": "Facts validated",
                "draft_assistant_output": "# Test Article\n\nThis is a test article.",
                "humanizer_assistant_output": "Humanized test content",
                "seo_assistant_output": {"title": "Test Article", "meta_description": "Test description", "keywords": ["test", "article"]},
                "multimedia_assistant_output": {"suggestions": [{"type": "image", "prompt": "test image"}]},
                "qa_assistant_output": {"questions": [{"question": "Test?", "answer": "Yes"}]},
                "image_renderer_assistant_output": {"images": [{"url": "test.jpg", "prompt": "test"}]}
            }
        
        test_result = {
            "workflow_id": workflow_id,
            "run_id": run_id,
            "test_type": "publish_script",
            "timestamp": workflow.now().timestamp(),
            "mock_data_keys": list(mock_pipeline_data.keys())
        }
        
        try:
            # Test publish activity
            workflow.logger.info("üîß Testing publish script...")
            
            publish_result = await workflow.execute_activity(
                "publish_activity",
                {
                    "assistant_config": {"name": "PublishScript", "function_key": "publish_script"},
                    "topic": mock_pipeline_data,
                    "current_date": workflow.now().isoformat(),
                    "previous_outputs": mock_pipeline_data
                },
                start_to_close_timeout=timedelta(minutes=2),
                schedule_to_close_timeout=timedelta(minutes=3),
                heartbeat_timeout=timedelta(seconds=30)
            )
            
            test_result.update({
                "success": publish_result.get("success", False),
                "result": publish_result,
                "formats_generated": publish_result.get("formats_generated", []),
                "files_saved": len(publish_result.get("files_saved", [])),
                "duration": workflow.now().timestamp() - test_result["timestamp"]
            })
            
            workflow.logger.info(f"‚úÖ PUBLISH_SCRIPT_TEST_WORKFLOW_SUCCESS: {len(publish_result.get('formats_generated', []))} formats generated")
            return test_result
            
        except Exception as e:
            test_result.update({
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__,
                "duration": workflow.now().timestamp() - test_result["timestamp"]
            })
            
            workflow.logger.error(f"‚ùå PUBLISH_SCRIPT_TEST_WORKFLOW_FAILED: {e}")
            return test_result


@workflow.defn
class ConnectionTestWorkflow:
    """Test workflow pro datab√°zov√© konexe"""
    
    @workflow.run
    async def run(self, connection_tests: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Testuje datab√°zov√© konexe a performance
        
        Args:
            connection_tests: Konfigurace test≈Ø
            
        Returns:
            V√Ωsledky test≈Ø konex√≠
        """
        workflow_id = workflow.info().workflow_id
        run_id = workflow.info().run_id
        
        workflow.logger.info("üîó CONNECTION_TEST_WORKFLOW_START")
        
        test_result = {
            "workflow_id": workflow_id,
            "run_id": run_id,
            "test_type": "connections",
            "timestamp": workflow.now().timestamp(),
            "config": connection_tests or {}
        }
        
        try:
            # Test r≈Øzn√Ωch typ≈Ø konex√≠ souƒçasnƒõ
            workflow.logger.info("üîß Testing multiple connection scenarios...")
            
            # Test 1: Z√°kladn√≠ konexe
            basic_result = await workflow.execute_activity(
                "db_debug_assistant",
                {"test_mode": "basic_connectivity"},
                start_to_close_timeout=timedelta(seconds=30),
                schedule_to_close_timeout=timedelta(minutes=1),
                heartbeat_timeout=timedelta(seconds=10)
            )
            
            # Test 2: Load assistants (typick√° operace)
            assistants_result = await workflow.execute_activity(
                "load_assistants_from_database", 
                "default_project_id",
                schedule_to_close_timeout=timedelta(seconds=30),
                heartbeat_timeout=timedelta(seconds=10)
            )
            
            # Test 3: Concurrent operations (v√≠ce aktivit najednou)
            concurrent_tests = []
            for i in range(3):
                concurrent_tests.append(
                    workflow.execute_activity(
                        "db_debug_assistant",
                        {"test_mode": f"concurrent_{i}"},
                        start_to_close_timeout=timedelta(seconds=30),
                        schedule_to_close_timeout=timedelta(minutes=1),
                        heartbeat_timeout=timedelta(seconds=10)
                    )
                )
            
            # Poƒçkat na dokonƒçen√≠ v≈°ech concurrent test≈Ø
            concurrent_results = []
            for test in concurrent_tests:
                try:
                    result = await test
                    concurrent_results.append({"success": True, "result": result})
                except Exception as e:
                    concurrent_results.append({"success": False, "error": str(e)})
            
            # Vyhodnocen√≠ v√Ωsledk≈Ø
            successful_concurrent = sum(1 for r in concurrent_results if r["success"])
            
            test_result.update({
                "success": basic_result.get("summary", {}).get("overall_success", False) and len(assistants_result.get("assistants", [])) > 0,
                "tests": {
                    "basic_connectivity": basic_result,
                    "load_assistants": {
                        "success": len(assistants_result.get("assistants", [])) > 0,
                        "assistants_count": len(assistants_result.get("assistants", [])),
                        "result": assistants_result
                    },
                    "concurrent_operations": {
                        "success": successful_concurrent == 3,
                        "successful_count": successful_concurrent,
                        "total_count": 3,
                        "results": concurrent_results
                    }
                },
                "duration": workflow.now().timestamp() - test_result["timestamp"]
            })
            
            workflow.logger.info(f"‚úÖ CONNECTION_TEST_WORKFLOW_SUCCESS: {successful_concurrent}/3 concurrent tests passed")
            return test_result
            
        except Exception as e:
            test_result.update({
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__,
                "duration": workflow.now().timestamp() - test_result["timestamp"]
            })
            
            workflow.logger.error(f"‚ùå CONNECTION_TEST_WORKFLOW_FAILED: {e}")
            return test_result


# Utility funkce pro snadn√© spou≈°tƒõn√≠ test≈Ø
def create_single_assistant_test_config(assistant_name: str, test_input: str = "Test vstup") -> Dict[str, Any]:
    """Vytvo≈ô√≠ konfiguraci pro test jednotliv√©ho asistenta"""
    assistant_configs = {
        "brief_assistant": {
            "name": "BriefAssistant",
            "function_key": "brief_assistant",
            "order": 1
        },
        "research_assistant": {
            "name": "ResearchAssistant", 
            "function_key": "research_assistant",
            "order": 2
        },
        "image_renderer_assistant": {
            "name": "ImageRendererAssistant",
            "function_key": "image_renderer_assistant", 
            "order": 9
        }
    }
    
    return {
        "assistant_config": assistant_configs.get(assistant_name, {
            "name": assistant_name,
            "function_key": assistant_name,
            "order": 1
        }),
        "test_input": test_input
    }


def create_comprehensive_test_suite() -> List[Dict[str, Any]]:
    """Vytvo≈ô√≠ kompletn√≠ sadu test≈Ø pro debugging"""
    return [
        {
            "workflow": "DatabaseTestWorkflow",
            "config": {"comprehensive": True},
            "description": "Kompletn√≠ test datab√°zov√Ωch operac√≠"
        },
        {
            "workflow": "ConnectionTestWorkflow", 
            "config": {"concurrent_tests": 3},
            "description": "Test datab√°zov√Ωch konex√≠ a concurrent operac√≠"
        },
        {
            "workflow": "ImageGenerationTestWorkflow",
            "config": {"test_prompts": ["Simple test image", "Red circle"]},
            "description": "Test generov√°n√≠ obr√°zk≈Ø"
        },
        {
            "workflow": "PublishScriptTestWorkflow",
            "config": {},
            "description": "Test publish scriptu s mock daty"
        },
        {
            "workflow": "SingleAssistantTestWorkflow",
            "config": create_single_assistant_test_config("brief_assistant", "Test ƒçl√°nek o testov√°n√≠"),
            "description": "Test BriefAssistant"
        }
    ]


if __name__ == "__main__":
    print("üîç Simple Debug Workflows ready for use")
    print("\nAvailable workflows:")
    print("1. SingleAssistantTestWorkflow - Test individual assistant")
    print("2. DatabaseTestWorkflow - Test database operations")
    print("3. ImageGenerationTestWorkflow - Test image generation")
    print("4. PublishScriptTestWorkflow - Test publish script")
    print("5. ConnectionTestWorkflow - Test database connections")
    
    test_suite = create_comprehensive_test_suite()
    print(f"\n‚úÖ Comprehensive test suite ready with {len(test_suite)} tests")