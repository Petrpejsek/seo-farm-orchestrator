import json
import os
import logging
from temporalio import workflow, activity
from datetime import timedelta
from typing import Dict, List, Any, Optional
import temporalio.common

# NastavenÃ­ loggingu
logger = logging.getLogger(__name__)

@workflow.defn
class AssistantPipelineWorkflow:
    @workflow.run
    async def run(self, topic: str, project_id: Optional[str] = None, csv_base64: Optional[str] = None, current_date: Optional[str] = None) -> dict:
        workflow_id = workflow.info().workflow_id
        run_id = workflow.info().run_id
        
        workflow.logger.info(f"ğŸš€ ASSISTANT_PIPELINE_STARTED: topic='{topic}' project_id={project_id} date='{current_date}' workflow_id={workflow_id} run_id={run_id}")
        
        # Inicializace stage logs pro tracking
        stage_logs = []
        pipeline_data = {
            "topic": topic,
            "project_id": project_id,
            "csv_base64": csv_base64,
            "current_date": current_date,
            "current_output": topic  # ZaÄneme s tÃ©matem jako prvnÃ­m vstupem
        }
        
        try:
            # 1ï¸âƒ£ NaÄtenÃ­ asistentÅ¯ z databÃ¡ze podle project_id
            stage_name = "load_assistants_config"
            stage_start = workflow.now().timestamp()
            workflow.logger.info(f"ğŸ“‹ STAGE_STARTED: {stage_name} for project_id={project_id}")
            stage_logs.append({"stage": stage_name, "status": "STARTED", "timestamp": stage_start})
            
            # ğŸš« STRICT PROJECT_ID VALIDATION - Å¾Ã¡dnÃ© fallbacky
            if not project_id:
                workflow.logger.error("âŒ project_id je povinnÃ½ pro naÄtenÃ­ asistentÅ¯ - workflow nelze spustit")
                raise Exception("âŒ project_id je povinnÃ½ pro naÄtenÃ­ asistentÅ¯ - workflow nelze spustit")
            
            assistants_config = await workflow.execute_activity(
                "load_assistants_from_database",
                project_id,
                schedule_to_close_timeout=timedelta(seconds=30),
                heartbeat_timeout=timedelta(seconds=10)
            )
            
            stage_duration = workflow.now().timestamp() - stage_start
            assistants_count = len(assistants_config.get("assistants", [])) if isinstance(assistants_config, dict) else len(assistants_config) if assistants_config else 0
            workflow.logger.info(f"âœ… STAGE_FINISHED: {stage_name} duration={stage_duration:.2f}s assistants_count={assistants_count}")
            stage_logs.append({"stage": stage_name, "status": "COMPLETED", "timestamp": workflow.now().timestamp(), "duration": stage_duration})

            # Extrakce asistentÅ¯ z Dict response
            if isinstance(assistants_config, dict):
                assistants = assistants_config.get("assistants", [])
                workflow.logger.info(f"ğŸ“‹ ExtrahovÃ¡no {len(assistants)} asistentÅ¯ z dict response")
            else:
                assistants = assistants_config if assistants_config else []
                workflow.logger.warning(f"âš ï¸ NeoÄekÃ¡vanÃ½ typ response: {type(assistants_config)}")
            
            if not assistants:
                workflow.logger.warning("âš ï¸ Å½Ã¡dnÃ­ asistenti nenalezeni - ukonÄuji workflow")
                raise Exception("Å½Ã¡dnÃ­ aktivnÃ­ asistenti nenalezeni pro danÃ½ projekt")

            # 2ï¸âƒ£ PostupnÃ© spuÅ¡tÄ›nÃ­ asistentÅ¯ podle poÅ™adÃ­
            for i, assistant in enumerate(assistants):
                # ğŸš« STRICT ASSISTANT VALIDATION - Å¾Ã¡dnÃ© fallbacky
                assistant_name = assistant.get("name")
                if not assistant_name:
                    workflow.logger.error(f"âŒ Asistent #{i+1} nemÃ¡ name - workflow nelze spustit")
                    raise Exception(f"âŒ Asistent #{i+1} nemÃ¡ name - workflow nelze spustit")
                
                function_key = assistant.get("function_key")
                if not function_key:
                    workflow.logger.error(f"âŒ Asistent {assistant_name} nemÃ¡ function_key - workflow nelze spustit")
                    raise Exception(f"âŒ Asistent {assistant_name} nemÃ¡ function_key - workflow nelze spustit")
                # NastavenÃ­ timeoutÅ¯ pro asistenta - prodlouÅ¾eno pro finÃ¡lnÃ­ asistenty
                timeout = 600  # 10 minut pro dlouhÃ© LLM odpovÄ›di
                heartbeat = 180  # 3 minuty heartbeat pro Claude API volÃ¡nÃ­
                
                stage_name = assistant_name
                stage_start = workflow.now().timestamp()
                workflow.logger.info(f"ğŸ¤– ASSISTANT_STARTED: {assistant_name} (function_key={function_key})")
                # Validace order - musÃ­ bÃ½t specifikovÃ¡n
                order = assistant.get("order")
                if order is None:
                    workflow.logger.error(f"âŒ Asistent {assistant_name} nemÃ¡ order - workflow nelze spustit")
                    raise Exception(f"âŒ Asistent {assistant_name} nemÃ¡ order - workflow nelze spustit")
                
                stage_logs.append({
                    "stage": assistant_name, 
                    "status": "STARTED", 
                    "timestamp": stage_start,
                    "function_key": function_key,
                    "order": order
                })
                
                try:
                    # ğŸ¯ INTELIGENTNÃ TOPIC SELECTION PRO KAÅ½DÃ‰HO ASISTENTA
                    if function_key == "draft_assistant":
                        # DraftAssistant dostÃ¡vÃ¡ kombinaci Brief + Research dat
                        brief_output = pipeline_data.get("brief_assistant_output", "")
                        research_output = pipeline_data.get("research_assistant_output", "")
                        
                        topic_input = f"""ğŸ“‹ BRIEF:
{brief_output}

ğŸ“Š RESEARCH DATA:
{research_output}"""
                        
                        workflow.logger.info(f"ğŸ¯ DraftAssistant vstup: Brief ({len(brief_output)} chars) + Research ({len(research_output)} chars)")
                    
                    # âœ… STANDARDNÃ SEKVENÄŒNÃ TOK pro vÅ¡echny asistenty
                    topic_input = pipeline_data["current_output"]
                    
                    # SpuÅ¡tÄ›nÃ­ assistant activity s konfiguraÄnÃ­mi parametry  
                    assistant_output = await workflow.execute_activity(
                        "execute_assistant",
                        {
                            "assistant_config": assistant,
                            "topic": topic_input,  # ğŸ”§ INTELIGENTNÃ TOPIC SELECTION
                            "current_date": pipeline_data["current_date"],  # ğŸ“… AKTUÃLNÃ DATUM PRO VÅ ECHNY ASISTENTY
                            "previous_outputs": {k: v for k, v in pipeline_data.items() if k.endswith("_output")}
                        },
                        start_to_close_timeout=timedelta(seconds=600),  # 10 minut pro finÃ¡lnÃ­ asistenty
                        schedule_to_close_timeout=timedelta(seconds=timeout),
                        heartbeat_timeout=timedelta(seconds=heartbeat),
                        retry_policy=temporalio.common.RetryPolicy(
                            initial_interval=timedelta(seconds=1),
                            maximum_interval=timedelta(seconds=10),
                            maximum_attempts=1,  # ğŸš« Å½ÃDNÃ‰ RETRY - strict fail fast
                            backoff_coefficient=1.0
                        )
                    )
                    
                    # ğŸš« STRICT OUTPUT VALIDATION - Å¾Ã¡dnÃ© fallbacky
                    if not assistant_output:
                        workflow.logger.error(f"âŒ Asistent {assistant_name} nevrÃ¡til Å¾Ã¡dnÃ½ vÃ½stup - workflow selhal")
                        raise Exception(f"âŒ Asistent {assistant_name} nevrÃ¡til Å¾Ã¡dnÃ½ vÃ½stup - workflow selhal")
                    
                    output_content = assistant_output.get("output")
                    if output_content is None:
                        workflow.logger.error(f"âŒ Asistent {assistant_name} nevrÃ¡til 'output' klÃ­Ä - workflow selhal")
                        raise Exception(f"âŒ Asistent {assistant_name} nevrÃ¡til 'output' klÃ­Ä - workflow selhal")
                    
                    # ğŸ”§ INTELIGENTNÃ UPDATE PIPELINE DATA
                    # UklÃ¡dÃ¡me vÃ½stup podle function_key pro pozdÄ›jÅ¡Ã­ kombinovÃ¡nÃ­
                    pipeline_data[f"{function_key}_output"] = output_content
                    
                    # âœ… STANDARDNÃ SEKVENÄŒNÃ TOK - aktualizace current_output
                    pipeline_data["current_output"] = output_content
                    
                    stage_duration = workflow.now().timestamp() - stage_start
                    workflow.logger.info(f"âœ… ASSISTANT_FINISHED: {assistant_name} duration={stage_duration:.2f}s output_length={len(str(output_content))}")
                    
                    # UloÅ¾enÃ­ ÃºspÄ›Å¡nÃ©ho stage logu s vÃ½stupem
                    stage_logs.append({
                        "stage": assistant_name, 
                        "status": "COMPLETED", 
                        "timestamp": workflow.now().timestamp(), 
                        "duration": stage_duration,
                        "function_key": function_key,
                        "order": order,
                        "output": output_content,
                        "metadata": assistant_output.get("metadata") or {}
                    })
                    
                except Exception as assistant_error:
                    stage_duration = workflow.now().timestamp() - stage_start
                    workflow.logger.error(f"âŒ ASSISTANT_FAILED: {assistant_name} duration={stage_duration:.2f}s error={str(assistant_error)}")
                    
                    # UloÅ¾enÃ­ failed stage logu
                    stage_logs.append({
                        "stage": assistant_name, 
                        "status": "FAILED", 
                        "timestamp": workflow.now().timestamp(), 
                        "duration": stage_duration,
                        "function_key": function_key,
                        "order": order,  # ğŸš« Å½ÃDNÃ FALLBACK - order uÅ¾ je validovanÃ½ vÃ½Å¡e
                        "error": str(assistant_error)
                    })
                    
                    # ğŸš« STRICT MODE - KAÅ½DÃ‰ SELHÃNÃ ASISTENTA UKONÄŒÃ WORKFLOW
                    workflow.logger.error(f"ğŸ’¥ ASSISTANT_FAILED: {assistant_name} - ukonÄuji workflow (strict mode)")
                    raise Exception(f"Asistent {assistant_name} selhal v strict mode: {str(assistant_error)}")

            # 3ï¸âƒ£ PÅ™Ã­prava finÃ¡lnÃ­ho vÃ½sledku
            final_result = {
                "topic": topic,
                "project_id": project_id,
                "workflow_id": workflow_id,
                "run_id": run_id,
                "final_output": pipeline_data["current_output"],
                "stage_logs": stage_logs,
                "assistants_executed": len([log for log in stage_logs if log.get("status") == "COMPLETED" and log.get("stage") != "load_assistants_config"]),
                "total_assistants": len(assistants),
                "pipeline_success": True
            }

            # 4ï¸âƒ£ UloÅ¾enÃ­ finÃ¡lnÃ­ho vÃ½sledku
            stage_name = "save_pipeline_result"
            stage_start = workflow.now().timestamp()
            workflow.logger.info(f"ğŸ’¾ STAGE_STARTED: {stage_name}")
            stage_logs.append({"stage": stage_name, "status": "STARTED", "timestamp": stage_start})
            
            try:
                saved_path = await workflow.execute_activity(
                    "save_output_to_json",
                    final_result,
                    schedule_to_close_timeout=timedelta(seconds=30)
                )
                
                stage_duration = workflow.now().timestamp() - stage_start
                workflow.logger.info(f"âœ… STAGE_FINISHED: {stage_name} duration={stage_duration:.2f}s saved_to={saved_path}")
                stage_logs.append({"stage": stage_name, "status": "COMPLETED", "timestamp": workflow.now().timestamp(), "duration": stage_duration})
                
                final_result["saved_to"] = saved_path
                
            except Exception as save_error:
                stage_duration = workflow.now().timestamp() - stage_start
                workflow.logger.warning(f"âš ï¸ SAVE_FAILED: {stage_name} duration={stage_duration:.2f}s error={str(save_error)}")
                stage_logs.append({"stage": stage_name, "status": "FAILED", "timestamp": workflow.now().timestamp(), "duration": stage_duration, "error": str(save_error)})
                # PokraÄujeme i bez uloÅ¾enÃ­

            # Update finÃ¡lnÃ­ch stage logs
            final_result["stage_logs"] = stage_logs
            
            total_duration = workflow.now().timestamp() - stage_logs[0]["timestamp"]
            completed_assistants = len([log for log in stage_logs if log.get("status") == "COMPLETED" and "Assistant" in log.get("stage", "")])
            
            # âœ… STRICT VALIDACE FINÃLNÃ PIPELINE - vÅ¡ichni naÄtenÃ­ asistenti musÃ­ bÃ½t dokonÄeni
            expected_assistants = len(assistants)
            if completed_assistants == expected_assistants:
                workflow.logger.info(f"ğŸ‰ ASSISTANT_PIPELINE_COMPLETED: total_duration={total_duration:.2f}s assistants_completed={completed_assistants}/{expected_assistants} âœ…")
                workflow.logger.info(f"ğŸ† FINÃLNÃ PIPELINE ÃšSPÄšÅ NÄš DOKONÄŒENA - vÅ¡ech {expected_assistants} asistentÅ¯ z databÃ¡ze probÄ›hlo!")
                
                # ğŸš€ AUTOMATICKÃ‰ SPUÅ TÄšNÃ PUBLISH SCRIPTU PO DOKONÄŒENÃ VÅ ECH ASISTENTÅ®
                try:
                    stage_name = "PublishScript"
                    stage_start = workflow.now().timestamp()
                    workflow.logger.info(f"ğŸš€ PUBLISH_SCRIPT_STARTED: po dokonÄenÃ­ {expected_assistants} asistentÅ¯")
                    stage_logs.append({"stage": stage_name, "status": "STARTED", "timestamp": stage_start})
                    
                    # PÅ™ipravenÃ­ vÅ¡ech vÃ½stupÅ¯ pro publish script
                    components = {
                        "brief_assistant_output": pipeline_data.get("brief_assistant_output", ""),
                        "research_assistant_output": pipeline_data.get("research_assistant_output", ""),
                        "fact_validator_assistant_output": pipeline_data.get("fact_validator_assistant_output", ""),
                        "draft_assistant_output": pipeline_data.get("draft_assistant_output", ""),
                        "humanizer_assistant_output": pipeline_data.get("humanizer_assistant_output", ""),
                        "seo_assistant_output": pipeline_data.get("seo_assistant_output", ""),
                        "multimedia_assistant_output": pipeline_data.get("multimedia_assistant_output", ""),
                        "qa_assistant_output": pipeline_data.get("qa_assistant_output", ""),
                        "image_renderer_assistant_output": pipeline_data.get("image_renderer_assistant_output", "")
                    }
                    
                    active_components = [k for k,v in components.items() if v]
                    workflow.logger.info(f"ğŸ”§ PUBLISH SCRIPT: {len(active_components)} aktivnÃ­ch komponent z pipeline")
                    
                    # SpuÅ¡tÄ›nÃ­ publish_activity
                    publish_output = await workflow.execute_activity(
                        "publish_activity",
                        {
                            "assistant_config": {"name": "PublishScript", "function_key": "publish_script"},
                            "topic": components,  # Pipeline data ze vÅ¡ech asistentÅ¯
                            "current_date": pipeline_data["current_date"],
                            "previous_outputs": {k: v for k, v in pipeline_data.items() if k.endswith("_output")}
                        },
                        start_to_close_timeout=timedelta(seconds=300),  # 5 minut pro deterministickÃ½ script
                        schedule_to_close_timeout=timedelta(seconds=300),
                        heartbeat_timeout=timedelta(seconds=60),
                        retry_policy=temporalio.common.RetryPolicy(
                            initial_interval=timedelta(seconds=1),
                            maximum_interval=timedelta(seconds=5),
                            maximum_attempts=1,  # ğŸš« Å½ÃDNÃ‰ RETRY - strict fail fast
                            backoff_coefficient=1.0
                        )
                    )
                    
                    stage_duration = workflow.now().timestamp() - stage_start
                    if publish_output and publish_output.get("success") == True:
                        workflow.logger.info(f"âœ… PUBLISH_SCRIPT_COMPLETED: duration={stage_duration:.2f}s")
                        stage_logs.append({"stage": stage_name, "status": "COMPLETED", "timestamp": workflow.now().timestamp(), "duration": stage_duration, "output": publish_output})
                        
                        # PÅ™idej publish output do finÃ¡lnÃ­ho vÃ½sledku
                        final_result["publish_output"] = publish_output
                    else:
                        workflow.logger.error(f"âŒ PUBLISH_SCRIPT_FAILED: duration={stage_duration:.2f}s")
                        workflow.logger.error(f"âŒ PUBLISH_OUTPUT_DEBUG: {publish_output}")
                        stage_logs.append({"stage": stage_name, "status": "FAILED", "timestamp": workflow.now().timestamp(), "duration": stage_duration, "error": "Publish script failed"})
                        
                except Exception as publish_error:
                    stage_duration = workflow.now().timestamp() - stage_start if 'stage_start' in locals() else 0
                    workflow.logger.error(f"âŒ PUBLISH_SCRIPT_ERROR: {str(publish_error)} duration={stage_duration:.2f}s")
                    stage_logs.append({"stage": "PublishScript", "status": "FAILED", "timestamp": workflow.now().timestamp(), "duration": stage_duration, "error": str(publish_error)})
                    # NepokraÄujeme s chybou - publish script nenÃ­ kritickÃ½ pro ÃºspÄ›ch pipeline
                
            else:
                # ğŸš« STRICT MODE - pokud neprobÄ›hly vÅ¡ichni asistenti, je to chyba
                error_msg = f"NEÃšPLNÃ PIPELINE - oÄekÃ¡vÃ¡no {expected_assistants} asistentÅ¯ z databÃ¡ze, dokonÄeno pouze {completed_assistants}"
                workflow.logger.error(f"âŒ {error_msg}")
                raise Exception(error_msg)
            
            return final_result
            
        except Exception as e:
            # Log failed pipeline
            current_stage = stage_logs[-1]["stage"] if stage_logs else "UNKNOWN"
            workflow.logger.error(f"âŒ PIPELINE_FAILED: topic='{topic}' project_id={project_id} error={str(e)} current_stage={current_stage}")
            
            # PÅ™idej failed log pokud jeÅ¡tÄ› nenÃ­
            if not stage_logs or stage_logs[-1].get("status") != "FAILED":
                stage_logs.append({
                    "stage": current_stage, 
                    "status": "FAILED", 
                    "timestamp": workflow.now().timestamp(), 
                    "error": str(e)
                })
            
            # ğŸš« STRICT FAILED RESULT - Å¾Ã¡dnÃ© fallbacky
            current_output = pipeline_data.get("current_output")
            if current_output is None:
                current_output = "PIPELINE_FAILED_NO_OUTPUT"
            
            failed_result = {
                "topic": topic,
                "project_id": project_id,
                "workflow_id": workflow_id,
                "run_id": run_id,
                "final_output": current_output,
                "stage_logs": stage_logs,
                "pipeline_success": False,
                "error": str(e),
                "failed_stage": current_stage
            }
            
            workflow.logger.error(f"ğŸ’¥ RETURNING_FAILED_RESULT: error={str(e)}")
            return failed_result 