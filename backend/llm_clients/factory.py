"""
LLM Client Factory pro multi-provider podporu.
Vytv√°≈ô√≠ spr√°vn√Ω client podle provideru a spravuje API kl√≠ƒçe.
"""

import logging
from typing import Dict, Any, List, Optional, Union
import os

from .base import BaseLLMClient
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))  # P≈ôid√° backend/ do PATH
from openai_client import OpenAIClient
from .claude_client import ClaudeClient
from .gemini_client import GeminiClient

logger = logging.getLogger(__name__)

class LLMClientFactory:
    """
    Factory pro vytv√°≈ôen√≠ LLM client≈Ø podle provideru.
    Spravuje API kl√≠ƒçe a poskytuje unified interface.
    """
    
    SUPPORTED_PROVIDERS = {
        "openai": OpenAIClient,
        "claude": ClaudeClient,
        "gemini": GeminiClient
    }
    
    @staticmethod
    def create_client(provider: str, api_key: Optional[str] = None) -> BaseLLMClient:
        """
        Vytvo≈ô√≠ LLM client pro dan√Ω provider.
        
        Args:
            provider: Provider name (openai, claude, gemini)
            api_key: Optional API key (pokud nen√≠ poskytnut, hled√° se v prost≈ôed√≠)
            
        Returns:
            BaseLLMClient instance
            
        Raises:
            ValueError: Nepodporovan√Ω provider
            Exception: Chyb√≠ API kl√≠ƒç
        """
        provider = provider.lower()
        
        if provider not in LLMClientFactory.SUPPORTED_PROVIDERS:
            supported = list(LLMClientFactory.SUPPORTED_PROVIDERS.keys())
            raise ValueError(f"Nepodporovan√Ω provider '{provider}'. Podporovan√©: {supported}")
        
        # Z√≠sk√°n√≠ API kl√≠ƒçe
        if not api_key:
            api_key = LLMClientFactory._get_api_key(provider)
        
        if not api_key or api_key == "Not found":
            raise Exception(f"API kl√≠ƒç pro {provider} nebyl nalezen")
        
        # Vytvo≈ôen√≠ clienta
        client_class = LLMClientFactory.SUPPORTED_PROVIDERS[provider]
        client = client_class(api_key)
        
        logger.info(f"‚úÖ LLM Client vytvo≈ôen pro provider: {provider}")
        return client
    
    @staticmethod
    def _get_api_key(provider: str) -> Optional[str]:
        """
        üö´ STRICT API KEY LOADING - ≈æ√°dn√© fallbacky
        Naƒçte API kl√≠ƒç POUZE z backend API.
        
        Args:
            provider: N√°zev provideru
            
        Returns:
            API kl√≠ƒç nebo None
            
        Raises:
            Exception: Pokud backend API nen√≠ dostupn√Ω
        """
        if not provider:
            raise Exception("Provider name pro API kl√≠ƒç nen√≠ specifikov√°n")
        
        try:
            # POUZE backend API - ≈æ√°dn√© fallbacky
            import requests
            api_base_url = os.getenv('API_BASE_URL')
            if not api_base_url:
                raise Exception("API_BASE_URL environment variable nen√≠ nastavena - LLM Factory nelze pou≈æ√≠t")
                
            response = requests.get(f"{api_base_url}/api-keys/{provider}", timeout=5)
            
            if response.ok:
                data = response.json()
                api_key = data.get("api_key")
                if api_key and api_key != "Not found":
                    logger.info(f"üîë API kl√≠ƒç pro {provider} naƒçten z backend API")
                    return api_key
            
            # ≈Ω√°dn√Ω fallback - pokud backend API nevr√°t√≠ kl√≠ƒç, selh√°n√≠
            logger.error(f"‚ùå Backend API nevr√°tilo platn√Ω API kl√≠ƒç pro {provider} (status: {response.status_code})")
            return None
            
        except requests.exceptions.RequestException as e:
            raise Exception(f"Nelze p≈ôipojit k backend API pro z√≠sk√°n√≠ API kl√≠ƒçe {provider}: {e}")
        except Exception as e:
            raise Exception(f"Kritick√° chyba p≈ôi naƒç√≠t√°n√≠ API kl√≠ƒçe {provider} z backend API: {e}")
    
    @staticmethod
    def get_supported_providers() -> List[str]:
        """Vr√°t√≠ seznam podporovan√Ωch provider≈Ø."""
        return list(LLMClientFactory.SUPPORTED_PROVIDERS.keys())
    
    @staticmethod
    def get_all_models() -> Dict[str, Dict[str, List[str]]]:
        """
        Vr√°t√≠ v≈°echny podporovan√© modely pro v≈°echny providery.
        
        Returns:
            Dict ve form√°tu:
            {
                "openai": {"text": ["gpt-4o", ...], "image": ["dall-e-3", ...]},
                "claude": {"text": ["claude-3.5-sonnet", ...], "image": []},
                ...
            }
        """
        all_models = {}
        
        for provider_name, client_class in LLMClientFactory.SUPPORTED_PROVIDERS.items():
            try:
                # Vytvo≈ô√≠m temporary instance s dummy API key pro z√≠sk√°n√≠ model≈Ø
                temp_client = client_class("dummy-key")
                all_models[provider_name] = temp_client.get_supported_models()
            except Exception as e:
                # üö´ ≈Ω√ÅDN√ù FALLBACK - pokud nelze naƒç√≠st modely, LLM Factory nesm√≠ fungovat
                logger.error(f"‚ùå Nepoda≈ôilo se naƒç√≠st modely pro {provider_name}: {e}")
                raise Exception(f"LLM Factory nen√≠ spr√°vnƒõ nakonfigurov√°n - nelze naƒç√≠st modely pro {provider_name}: {e}")
        
        return all_models
    
    @staticmethod
    def get_provider_parameters(provider: str) -> List[str]:
        """
        Vr√°t√≠ podporovan√© parametry pro dan√Ω provider.
        
        Args:
            provider: Provider name
            
        Returns:
            List parametr≈Ø
        """
        provider = provider.lower()
        
        if provider not in LLMClientFactory.SUPPORTED_PROVIDERS:
            supported = list(LLMClientFactory.SUPPORTED_PROVIDERS.keys())
            raise ValueError(f"Nepodporovan√Ω provider '{provider}' pro z√≠sk√°n√≠ parametr≈Ø. Podporovan√©: {supported}")
        
        try:
            client_class = LLMClientFactory.SUPPORTED_PROVIDERS[provider]
            temp_client = client_class("dummy-key")
            return temp_client.get_supported_parameters()
        except Exception as e:
            # üö´ ≈Ω√ÅDN√ù FALLBACK - pokud nelze naƒç√≠st parametry, LLM Factory nesm√≠ fungovat
            logger.error(f"‚ùå Nepoda≈ôilo se naƒç√≠st parametry pro {provider}: {e}")
            raise Exception(f"LLM Factory nen√≠ spr√°vnƒõ nakonfigurov√°n - nelze naƒç√≠st parametry pro {provider}: {e}")
    
    @staticmethod
    def validate_model_for_provider(provider: str, model: str) -> bool:
        """
        Ovƒõ≈ô√≠, zda je model podporov√°n dan√Ωm providerem.
        
        Args:
            provider: Provider name
            model: Model name
            
        Returns:
            True pokud je model podporov√°n
        """
        provider = provider.lower()
        
        if provider not in LLMClientFactory.SUPPORTED_PROVIDERS:
            supported = list(LLMClientFactory.SUPPORTED_PROVIDERS.keys())
            raise ValueError(f"Nepodporovan√Ω provider '{provider}' pro validaci modelu. Podporovan√©: {supported}")
        
        try:
            client_class = LLMClientFactory.SUPPORTED_PROVIDERS[provider]
            temp_client = client_class("dummy-key")
            return temp_client.validate_model(model)
        except Exception as e:
            # üö´ ≈Ω√ÅDN√ù FALLBACK - pokud validace sel≈æe, LLM Factory nesm√≠ ≈ô√≠ct "false" ale vyhodit chybu
            logger.error(f"‚ùå Nepoda≈ôilo se ovƒõ≈ôit model {model} pro {provider}: {e}")
            raise Exception(f"LLM Factory nen√≠ spr√°vnƒõ nakonfigurov√°n - nelze ovƒõ≈ôit model {model} pro {provider}: {e}")