import logging
from typing import Optional
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Query, Path
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from temporal_client import start_seo_pipeline, list_workflows, get_workflow_result, describe_workflow_execution, terminate_workflow

# Import nov√Ωch API router≈Ø
from api.routes.project import router as project_router
from api.routes.assistant import router as assistant_router
from api.routes.workflow_run import router as workflow_run_router
from api.routes.api_keys import router as api_keys_router

# Import datab√°zov√©ho p≈ôipojen√≠
from api.database import connect_database, disconnect_database

# Import datab√°zov√©ho p≈ôipojen√≠ a workflow run API
from api.database import get_prisma_client

# Nastaven√≠ loggingu
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Lifespan context manager pro startup/shutdown ud√°losti
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    await connect_database()
    logger.info("‚úÖ Datab√°ze p≈ôipojena p≈ôi startu")
    yield
    # Shutdown
    await disconnect_database()
    logger.info("üîÑ Datab√°ze odpojen√° p≈ôi ukonƒçen√≠")

# FastAPI instance s lifespan
app = FastAPI(
    title="SEO Farm Orchestrator Backend",
    description="FastAPI backend s Temporal.io integrac√≠ pro SEO content generation",
    version="0.1.0",
    lifespan=lifespan
)

# CORS middleware - povolen√≠ p≈ô√≠stupu z frontendu
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",  # Frontend development server (primary)
        "http://localhost:3001",  # Frontend development server (fallback)
        "http://127.0.0.1:3000",
        "http://127.0.0.1:3001",
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# Pydantic modely pro validaci
class CSVData(BaseModel):
    name: str = Field(..., description="N√°zev CSV souboru")
    content: str = Field(..., description="Base64 encoded obsah CSV souboru")

class PipelineRequest(BaseModel):
    topic: str = Field(..., min_length=1, description="T√©ma pro SEO zpracov√°n√≠")
    project_id: Optional[str] = Field(None, description="ID projektu pro propojen√≠ workflow")
    csv: Optional[CSVData] = Field(None, description="Voliteln√Ω CSV soubor")

class PipelineResponse(BaseModel):
    status: str = Field(..., description="Status spu≈°tƒõn√≠ workflow")
    workflow_id: str = Field(..., description="ID Temporal workflow")
    run_id: str = Field(..., description="Run ID Temporal workflow")
    project_id: Optional[str] = Field(None, description="ID projektu")
    database_id: Optional[str] = Field(None, description="ID z√°znamu v datab√°zi")

class TerminateWorkflowRequest(BaseModel):
    reason: str = Field(default="Manually terminated by user", description="D≈Øvod ukonƒçen√≠ workflow")

# Registrace router≈Ø
app.include_router(project_router)
app.include_router(assistant_router)
app.include_router(workflow_run_router)
app.include_router(api_keys_router)

# Datab√°zov√© p≈ôipojen√≠ je nyn√≠ spravov√°no p≈ôes lifespan context manager

@app.get("/")
async def root():
    """Health check endpoint pro ovƒõ≈ôen√≠ stavu API"""
    return {"message": "SEO Farm Orchestrator Backend API", "status": "running"}

@app.post("/api/pipeline-run", response_model=PipelineResponse)
async def pipeline_run(request: PipelineRequest):
    """
    Spust√≠ SEO pipeline workflow p≈ôes Temporal a vytvo≈ô√≠ z√°znam v datab√°zi.
    
    Args:
        request: Pipeline request s t√©matem, project_id a voliteln√Ωm CSV
        
    Returns:
        Response s workflow ID, run ID a datab√°zov√Ωm ID
        
    Raises:
        HTTPException: 400 pokud projekt neexistuje, 500 pokud chyb√≠ p≈ôipojen√≠ k Temporal
    """
    try:
        logger.info(f"üöÄ Spou≈°t√≠m SEO pipeline:")
        logger.info(f"   üìã T√©ma: {request.topic}")
        logger.info(f"   üèóÔ∏è Project ID: {request.project_id}")
        logger.info(f"   üìÑ CSV: {'‚úÖ P≈ôilo≈æen' if request.csv else '‚ùå ≈Ω√°dn√Ω'}")
        
        # Ovƒõ≈ôen√≠ existence projektu pokud je zad√°n project_id
        database_id = None
        if request.project_id:
            try:
                prisma = await get_prisma_client()
                project = await prisma.project.find_unique(where={"id": request.project_id})
                if not project:
                    logger.error(f"‚ùå Projekt s ID {request.project_id} nenalezen")
                    raise HTTPException(status_code=400, detail=f"Projekt s ID {request.project_id} neexistuje")
                logger.info(f"‚úÖ Projekt ovƒõ≈ôen: {project.name}")
            except HTTPException:
                raise
            except Exception as e:
                logger.error(f"‚ùå Chyba p≈ôi ovƒõ≈ôov√°n√≠ projektu: {str(e)}")
                raise HTTPException(status_code=500, detail=f"Chyba p≈ôi ovƒõ≈ôov√°n√≠ projektu: {str(e)}")
        
        # Extrakce CSV obsahu pokud existuje
        csv_base64 = None
        if request.csv:
            csv_base64 = request.csv.content
            logger.info(f"üìÑ CSV soubor p≈ôilo≈æen: {request.csv.name}")
        
        # Spu≈°tƒõn√≠ Temporal workflow
        logger.info("üîå P≈ôipojuji se k Temporal serveru...")
        workflow_id, run_id = await start_seo_pipeline(
            topic=request.topic,
            project_id=request.project_id,
            csv_base64=csv_base64
        )
        
        logger.info(f"‚úÖ Temporal workflow √∫spƒõ≈°nƒõ spu≈°tƒõn:")
        logger.info(f"   üÜî Workflow ID: {workflow_id}")
        logger.info(f"   üèÉ Run ID: {run_id}")
        
        # Vytvo≈ôen√≠ z√°znamu v datab√°zi pokud je zad√°n project_id
        if request.project_id:
            try:
                # Import WorkflowRunCreate modelu a create_workflow_run funkce
                from api.routes.workflow_run import WorkflowRunCreate, create_workflow_run
                
                # Vytvo≈ôen√≠ z√°znamu workflow run v datab√°zi
                workflow_run_data = WorkflowRunCreate(
                    projectId=request.project_id,
                    topic=request.topic,
                    runId=run_id,
                    workflowId=workflow_id
                )
                
                logger.info(f"üíæ Ukl√°d√°m workflow do datab√°ze:")
                logger.info(f"   üìù Topic: {request.topic}")
                logger.info(f"   üèóÔ∏è Project ID: {request.project_id}")
                logger.info(f"   üÜî Workflow ID: {workflow_id}")
                logger.info(f"   üèÉ Run ID: {run_id}")
                
                # Skuteƒçn√© vol√°n√≠ API endpointu pro vytvo≈ôen√≠ datab√°zov√©ho z√°znamu
                workflow_response = await create_workflow_run(workflow_run_data)
                database_id = workflow_response.id
                
                logger.info(f"‚úÖ Workflow run skuteƒçnƒõ vytvo≈ôen v datab√°zi s ID: {database_id}")
                
            except Exception as e:
                logger.error(f"‚ö†Ô∏è Chyba p≈ôi vytv√°≈ôen√≠ datab√°zov√©ho z√°znamu: {str(e)}")
                logger.info("‚ÑπÔ∏è Workflow pokraƒçuje, ale bez datab√°zov√©ho z√°znamu")
        
        logger.info(f"üéâ Pipeline √∫spƒõ≈°nƒõ spu≈°tƒõna pro t√©ma: '{request.topic}'")
        
        return PipelineResponse(
            status="started",
            workflow_id=workflow_id,
            run_id=run_id,
            project_id=request.project_id,
            database_id=database_id
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Kritick√° chyba p≈ôi spu≈°tƒõn√≠ pipeline:")
        logger.error(f"   üìã T√©ma: {request.topic}")
        logger.error(f"   üèóÔ∏è Project ID: {request.project_id}")
        logger.error(f"   üö® Chyba: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Chyba p≈ôi spu≈°tƒõn√≠ workflow: {str(e)}"
        )

@app.get("/api/workflows")
async def get_workflows(limit: int = Query(30, description="Maxim√°ln√≠ poƒçet v√Ωsledk≈Ø")):
    """
    Naƒçte seznam workflow executions z Temporal serveru.
    
    Args:
        limit: Maxim√°ln√≠ poƒçet v√Ωsledk≈Ø (default 30)
        
    Returns:
        JSON s workflows seznamem
        
    Raises:
        HTTPException: Appropriate HTTP status based on error type
    """
    logger.info(f"üß† Dotaz na Temporal: naƒç√≠t√°m {limit} workflows...")
    
    try:
        # Vol√°n√≠ funkce pro naƒçten√≠ workflows
        workflows = await list_workflows(limit=limit)
        
        if not workflows:
            logger.info("üì≠ ≈Ω√°dn√© workflows nenalezeny - vr√°c√≠m pr√°zdn√© pole")
            return {"workflows": []}
        
        logger.info(f"‚úÖ Vr√°ceno {len(workflows)} workflow≈Ø")
        return {"workflows": workflows}
        
    except ConnectionError as e:
        logger.error(f"‚ùå Temporal server nedostupn√Ω: {str(e)}")
        raise HTTPException(
            status_code=503,
            detail="Temporal server je moment√°lnƒõ nedostupn√Ω. Zkuste to znovu pozdƒõji."
        )
    except ValueError as e:
        logger.error(f"‚ùå Neplatn√° data z Temporal: {str(e)}")
        raise HTTPException(
            status_code=422,
            detail=f"Chyba zpracov√°n√≠ dat: {str(e)}"
        )
    except Exception as e:
        # Loguj cel√Ω stacktrace pro debug
        import traceback
        logger.error(f"‚ùå Neoƒçek√°v√°n√° chyba p≈ôi naƒç√≠t√°n√≠ workflows:")
        logger.error(f"   Typ: {type(e).__name__}")
        logger.error(f"   Zpr√°va: {str(e)}")
        logger.error(f"   Stacktrace: {traceback.format_exc()}")
        
        raise HTTPException(
            status_code=500,
            detail=f"Chyba p≈ôi naƒç√≠t√°n√≠ workflows: {str(e)}"
        )

@app.get("/api/workflow-result/{workflow_id}/{run_id}")
async def get_workflow_result_endpoint(
    workflow_id: str = Path(..., description="ID workflow"),
    run_id: str = Path(..., description="Run ID workflow")
):
    """
    Z√≠sk√° v√Ωsledek dokonƒçen√©ho workflow z Temporal serveru s diagnostick√Ωmi informacemi.
    
    Args:
        workflow_id: ID workflow
        run_id: Run ID workflow
        
    Returns:
        JSON s workflow v√Ωsledkem, metadata a diagnostick√Ωmi informacemi
        
    Raises:
        HTTPException: 404 pokud workflow neexistuje, 503 pokud Temporal nen√≠ dostupn√Ω
    """
    logger.info(f"üì§ Fetch result: workflow_id={workflow_id}, run_id={run_id}")
    
    try:
        # Nejd≈ô√≠v z√≠sk√°me z√°kladn√≠ v√Ωsledek workflow
        result_data = await get_workflow_result(workflow_id=workflow_id, run_id=run_id)
        
        # Aktualizace statusu v datab√°zi na z√°kladƒõ Temporal v√Ωsledku
        await update_workflow_status_in_database(workflow_id=workflow_id, run_id=run_id, result_data=result_data)
        
        # P≈ôid√°me diagnostick√© informace pro RUNNING i TIMED_OUT workflow  
        if result_data.get("status") in ["RUNNING", "TIMED_OUT", "FAILED"]:
            try:
                diagnostic_info = await describe_workflow_execution(workflow_id=workflow_id, run_id=run_id)
                
                # Slouƒç√≠me diagnostick√© informace s v√Ωsledkem
                result_data.update({
                    "current_phase": diagnostic_info.get("current_phase", "Unknown"),
                    "current_activity_type": diagnostic_info.get("current_activity_type"),
                    "elapsed_seconds": diagnostic_info.get("elapsed_seconds", 0),
                    "activity_elapsed_seconds": diagnostic_info.get("activity_elapsed_seconds", 0),
                    "activity_attempt": diagnostic_info.get("activity_attempt", 0),
                    "is_long_running": diagnostic_info.get("is_long_running", False),
                    "warning": diagnostic_info.get("warning", False),
                    "workflow_history": diagnostic_info.get("workflow_history", [])  # üîç AUDIT: Historie aktivit
                })
                
                logger.info(f"üéØ Current phase: {diagnostic_info.get('current_phase')} ({diagnostic_info.get('elapsed_seconds', 0)/60:.1f} min)")
                
            except Exception as diag_error:
                logger.warning(f"‚ö†Ô∏è Diagnostika selhala: {str(diag_error)}")
                # P≈ôid√°me alespo≈à basic info
                result_data.update({
                    "current_phase": "Unknown (diagnostic failed)",
                    "warning": False,
                    "diagnostic_error": str(diag_error)
                })
        
        logger.info(f"‚úÖ Result loaded: status={result_data.get('status')}")
        return result_data
        
    except ValueError as e:
        # Workflow neexistuje nebo nen√≠ dokonƒçen
        logger.warning(f"‚ö†Ô∏è Workflow nenalezen: {str(e)}")
        raise HTTPException(
            status_code=404,
            detail={
                "error": "Workflow nenalezen nebo v√Ωstup nen√≠ k dispozici",
                "message": str(e)
            }
        )
    except ConnectionError as e:
        # Temporal server nen√≠ dostupn√Ω
        logger.error(f"‚ùå Temporal connection error: {str(e)}")
        raise HTTPException(
            status_code=503,
            detail={
                "error": "Temporal server nen√≠ dostupn√Ω",
                "message": "Zkuste to pozdƒõji nebo kontaktujte administr√°tora"
            }
        )
    except Exception as e:
        # Ostatn√≠ chyby
        logger.error(f"‚ùå Error: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail={
                "error": "Nastala chyba p≈ôi naƒç√≠t√°n√≠ v√Ωstupu",
                "message": str(e)
            }
        )

@app.post("/api/workflow-terminate/{workflow_id}/{run_id}")
async def terminate_workflow_endpoint(
    workflow_id: str = Path(..., description="ID workflow"),
    run_id: str = Path(..., description="Run ID workflow"),
    request: TerminateWorkflowRequest = None
):
    """
    Ukonƒç√≠ bƒõ≈æ√≠c√≠ workflow execution.
    
    Args:
        workflow_id: ID workflow
        run_id: Run ID workflow  
        request: Po≈æadavek s d≈Øvodem ukonƒçen√≠
        
    Returns:
        JSON s potvrzen√≠m ukonƒçen√≠
        
    Raises:
        HTTPException: 404 pokud workflow neexistuje nebo nen√≠ RUNNING, 503 pokud Temporal nen√≠ dostupn√Ω
    """
    reason = request.reason if request else "Manually terminated by user"
    logger.info(f"‚õî Terminate request: workflow_id={workflow_id}, run_id={run_id}, reason={reason}")
    
    try:
        result = await terminate_workflow(workflow_id=workflow_id, run_id=run_id, reason=reason)
        logger.info(f"‚úÖ Workflow terminated successfully: {workflow_id}")
        return result
        
    except ValueError as e:
        # Workflow neexistuje nebo nen√≠ RUNNING
        logger.warning(f"‚ö†Ô∏è Cannot terminate workflow: {str(e)}")
        raise HTTPException(
            status_code=404,
            detail={
                "error": "Workflow nelze ukonƒçit",
                "message": str(e)
            }
        )
    except ConnectionError as e:
        # Temporal server nen√≠ dostupn√Ω
        logger.error(f"‚ùå Temporal connection error: {str(e)}")
        raise HTTPException(
            status_code=503,
            detail={
                "error": "Temporal server nen√≠ dostupn√Ω",
                "message": "Zkuste to pozdƒõji nebo kontaktujte administr√°tora"
            }
        )
    except Exception as e:
        # Ostatn√≠ chyby
        logger.error(f"‚ùå Error terminating workflow: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail={
                "error": "Nastala chyba p≈ôi ukonƒçov√°n√≠ workflow",
                "message": str(e)
            }
        )

async def update_workflow_status_in_database(workflow_id: str, run_id: str, result_data: dict):
    """
    Aktualizuje status workflow v datab√°zi na z√°kladƒõ informac√≠ z Temporal serveru.
    
    Args:
        workflow_id: ID workflow z Temporal
        run_id: Run ID workflow z Temporal 
        result_data: V√Ωsledek z get_workflow_result
    """
    try:
        from api.routes.workflow_run import get_prisma_client
        from datetime import datetime
        
        logger.info(f"üîÑ Aktualizuji status workflow v datab√°zi: {workflow_id}")
        
        prisma = await get_prisma_client()
        
        # Najdeme workflow run podle workflowId a runId
        existing_run = await prisma.workflowrun.find_unique(
            where={
                "workflowId_runId": {
                    "workflowId": workflow_id,
                    "runId": run_id
                }
            }
        )
        
        if not existing_run:
            logger.warning(f"‚ö†Ô∏è Workflow run {workflow_id}/{run_id} nenalezen v datab√°zi pro aktualizaci")
            return
        
        # P≈ôiprav√≠me data pro aktualizaci
        update_fields = {}
        temporal_status = result_data.get("status")
        
        # Mapov√°n√≠ Temporal status≈Ø na na≈°e datab√°zov√© statusy
        if temporal_status == "COMPLETED":
            update_fields["status"] = "COMPLETED"
            if result_data.get("end_time"):
                update_fields["finishedAt"] = datetime.fromisoformat(result_data["end_time"].replace('Z', '+00:00'))
        elif temporal_status == "FAILED":
            update_fields["status"] = "FAILED"
            if result_data.get("end_time"):
                update_fields["finishedAt"] = datetime.fromisoformat(result_data["end_time"].replace('Z', '+00:00'))
        elif temporal_status == "TIMED_OUT":
            update_fields["status"] = "TIMED_OUT"
            if result_data.get("end_time"):
                update_fields["finishedAt"] = datetime.fromisoformat(result_data["end_time"].replace('Z', '+00:00'))
        elif temporal_status == "RUNNING":
            update_fields["status"] = "RUNNING"
        else:
            update_fields["status"] = temporal_status or "UNKNOWN"
        
        # P≈ôid√°me v√Ωsledek jako JSON pokud existuje
        if result_data.get("result"):
            import json
            update_fields["resultJson"] = json.dumps(result_data["result"], ensure_ascii=False)
        
        # P≈ôid√°me stage informace pokud existuj√≠
        if result_data.get("stage_logs"):
            completed_stages = len([log for log in result_data["stage_logs"] if log.get("status") == "COMPLETED"])
            total_stages = len(result_data["stage_logs"])
            update_fields["stageCount"] = completed_stages
            update_fields["totalStages"] = total_stages
        
        # Aktualizace v datab√°zi
        updated_run = await prisma.workflowrun.update(
            where={"id": existing_run.id},
            data=update_fields
        )
        
        logger.info(f"‚úÖ Workflow run aktualizov√°n: {updated_run.status} ({updated_run.stageCount}/{updated_run.totalStages} stages)")
        
    except Exception as e:
        logger.error(f"‚ö†Ô∏è Chyba p≈ôi aktualizaci workflow statusu v datab√°zi: {str(e)}")
        # Nebudeme hadit exception, aby to nerozhodilo hlavn√≠ flow


@app.get("/health")
async def health_check():
    """Health check endpoint pro monitoring"""
    return {"status": "healthy", "service": "seo-farm-backend"} 