"""
PublishAssistant - FinÃ¡lnÃ­ kompilace ÄlÃ¡nku do JSON formÃ¡tu pro landing page
"""

import json
import logging
from typing import Dict, Any, Optional
from openai import OpenAI
from llm_factory import LLMClient

logger = logging.getLogger(__name__)

async def publish_assistant(input_data: Dict[str, Any], assistant_id: Optional[str] = None) -> str:
    """
    Zkompiluje vÅ¡echny vÃ½stupy z pipeline do finÃ¡lnÃ­ho JSON formÃ¡tu pro landing page.
    
    STRIKTNÃ POÅ½ADAVKY:
    - Å½ÃDNÃ‰ fallback mechanismy
    - PÅ™esnÃ½ JSON formÃ¡t pro landing pages
    - Extrakce dat ze vÅ¡ech 8 asistentÅ¯
    - Validace povinnÃ½ch komponent
    
    Args:
        input_data: Obsahuje topic a previous_outputs ze vÅ¡ech asistentÅ¯
        assistant_id: ID asistenta (optional)
    
    Returns:
        JSON string s finÃ¡lnÃ­m ÄlÃ¡nkem
    """
    logger.info("ğŸš€ PublishAssistant: Kompilace finÃ¡lnÃ­ho ÄlÃ¡nku")
    
    try:
        # Extrakce zÃ¡kladnÃ­ch dat
        topic = input_data.get("topic", "")
        previous_outputs = input_data.get("previous_outputs", {})
        
        logger.info(f"ğŸ“¥ Previous outputs klÃ­Äe: {list(previous_outputs.keys())}")
        
        # === EXTRAKCE DAT ZE VÅ ECH 8 ASISTENTÅ® ===
        
        # 1. BRIEF DATA
        brief_data = previous_outputs.get("brief_assistant_output", "")
        logger.info(f"ğŸ“‹ Brief data: {len(str(brief_data))} znakÅ¯")
        
        # 2. RESEARCH DATA  
        research_data = previous_outputs.get("research_assistant_output", "")
        logger.info(f"ğŸ” Research data: {len(str(research_data))} znakÅ¯")
        
        # 3. DRAFT/HUMANIZER HTML CONTENT (priorita Humanizer)
        html_content = ""
        if "humanizer_assistant_output" in previous_outputs:
            html_content = previous_outputs["humanizer_assistant_output"]
            logger.info("ğŸ“ PouÅ¾Ã­vÃ¡m HTML z HumanizerAssistant")
        elif "draft_assistant_output" in previous_outputs:
            html_content = previous_outputs["draft_assistant_output"]
            logger.info("ğŸ“ PouÅ¾Ã­vÃ¡m HTML z DraftAssistant")
        
        # 4. SEO METADATA
        seo_metadata = previous_outputs.get("seo_assistant_output", "")
        logger.info(f"ğŸ¯ SEO metadata: {len(str(seo_metadata))} znakÅ¯")
        
        # 5. FACT VALIDATION
        validated_facts = previous_outputs.get("fact_validator_assistant_output", "")
        logger.info(f"âœ… Validated facts: {len(str(validated_facts))} znakÅ¯")
        
        # 6. QA DATA
        qa_data = previous_outputs.get("qa_assistant_output", "")
        logger.info(f"ğŸ” QA data: {len(str(qa_data))} znakÅ¯")
        
        # 7. MULTIMEDIA DATA
        multimedia_data = previous_outputs.get("multimedia_assistant_output", "")
        logger.info(f"ğŸ¨ Multimedia data: {len(str(multimedia_data))} znakÅ¯")
        
        # 8. GENERATED IMAGES
        generated_images = previous_outputs.get("image_renderer_assistant_output", "")
        logger.info(f"ğŸ–¼ï¸ Generated images: {len(str(generated_images))} znakÅ¯")
        
        # STRICT VALIDATION - Å½ÃDNÃ‰ FALLBACKY!
        if not html_content:
            raise Exception("âŒ PublishAssistant: ChybÃ­ HTML content z DraftAssistant nebo HumanizerAssistant")
        if not seo_metadata:
            raise Exception("âŒ PublishAssistant: ChybÃ­ SEO metadata z SEOAssistant")
        
        logger.info("âœ… VÅ¡echny povinnÃ© komponenty nalezeny")
        
        # === LLM CLIENT SETUP ===
        from config import get_llm_config
        llm_config = get_llm_config()
        
        client = OpenAI(api_key=llm_config["openai"]["api_key"])
        
        # PÅ˜ESNÃ FORMÃT JSON PRO LANDING PAGE
        prompt = f"""VytvoÅ™ JSON pro landing page v PÅ˜ESNÄš tomto formÃ¡tu z poskytnutÃ½ch dat:

ğŸ“¥ VSTUPNÃ DATA:
HTML CONTENT: {html_content}
SEO METADATA: {seo_metadata}
QA DATA: {qa_data if qa_data else "NedostupnÃ©"}
GENERATED IMAGES: {generated_images if generated_images else "NedostupnÃ©"}

ğŸ¯ POÅ½ADOVANÃ VÃSTUP - PÅ˜ESNÄš TENTO FORMÃT:
{{
  "title": "NÃ¡zev strÃ¡nky z SEO metadata",
  "slug": "url-slug-bez-diakritiky-z-seo",
  "language": "cs",
  "meta": {{
    "description": "SEO popis z metadata",
    "keywords": ["klÃ­ÄovÃ©", "slovo1", "slovo2"]
  }},
  "content_html": "HTML obsah PÅ˜ESNÄš jak je poskytnut",
  "visuals": [
    {{
      "url": "https://url-obrazku.jpg",
      "alt_text": "Popis obrÃ¡zku", 
      "description": "DetailnÃ­ popis"
    }}
  ],
  "faq": [
    {{
      "question": "OtÃ¡zka?",
      "answer": "OdpovÄ›Ä na otÃ¡zku"
    }}
  ],
  "facts_and_sources": [
    {{
      "fact": "OvÄ›Å™enÃ½ fakt",
      "source": "Zdroj nebo URL"
    }}
  ],
  "original_brief": {{
    "topic": "{topic}",
    "research_summary": "ShrnutÃ­ research dat",
    "creation_date": "2025-08-03"
  }},
  "schema_org": {{
    "@context": "https://schema.org",
    "@type": "Article",
    "headline": "Nadpis ÄlÃ¡nku"
  }},
  "format": "html"
}}

ğŸ“‹ INSTRUKCE:
âœ… Extrahuj title, slug, description, keywords z SEO metadata
âœ… VloÅ¾ content_html PÅ˜ESNÄš bez Ãºprav
âœ… VytvoÅ™ visuals array z generated_images (pokud jsou dostupnÃ©)
âœ… VytvoÅ™ FAQ z QA dat (pokud jsou dostupnÃ¡)
âœ… keywords MUSÃ bÃ½t array stringÅ¯
âœ… VytvoÅ™ facts_and_sources z validated facts
âœ… ZÃ¡kladnÃ­ schema_org s Article type

âŒ NESMÃ OBSAHOVAT:
- Å½Ã¡dnÃ½ text pÅ™ed/po JSON
- Å½Ã¡dnÃ© markdown formÃ¡tovÃ¡nÃ­
- Å½Ã¡dnÃ© komentÃ¡Å™e
- Å½Ã¡dnÃ© pipeline wrappery

OUTPUT: Pouze validnÃ­ JSON objekt!"""
    
    try:
        response = client.chat.completions.create(
                model="gpt-4o",
            messages=[
                    {"role": "system", "content": "Jsi JSON export asistent pro landing pages. VytvoÅ™Ã­Å¡ POUZE ÄistÃ½ JSON objekt bez jakÃ©hokoli dalÅ¡Ã­ho textu. PouÅ¾Ã­vej vstupnÃ­ data pÅ™esnÄ› jak jsou poskytnutÃ¡. NeformÃ¡tuj markdown, nevytvÃ¡Å™ej komentÃ¡Å™e."},
                {"role": "user", "content": prompt}
            ],
                temperature=0.2,
                top_p=0.8,
                max_tokens=8000
        )
        
        published_content = response.choices[0].message.content.strip()
            
            # Validace Å¾e je to validnÃ­ JSON
            try:
                json.loads(published_content)
                logger.info(f"âœ… FinÃ¡lnÃ­ ÄlÃ¡nek JSON pÅ™ipraven: {len(published_content)} znakÅ¯")
            except json.JSONDecodeError as e:
                logger.error(f"âŒ LLM nevrÃ¡til validnÃ­ JSON: {e}")
                raise Exception(f"âŒ PublishAssistant: LLM nevrÃ¡til validnÃ­ JSON: {e}")
        
        return published_content
        
    except Exception as e:
            logger.error(f"âŒ PublishAssistant LLM volÃ¡nÃ­ selhalo: {e}")
            raise Exception(f"âŒ PublishAssistant failed pÅ™i kompilaci: {e}")
        
    except Exception as e:
        logger.error(f"âŒ PublishAssistant celkovÃ© selhÃ¡nÃ­: {e}")
        raise Exception(f"âŒ PublishAssistant failed: {e}")