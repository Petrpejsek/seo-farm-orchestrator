"""
PublishAssistant - Publishing krok v SEO pipeline
PÅ™ipravuje content pro publikaci a zajiÅ¡Å¥uje finÃ¡lnÃ­ formÃ¡tovÃ¡nÃ­.
"""

import json
import logging
import os
from typing import Dict, Any, Optional
from openai import OpenAI
from datetime import datetime

# Import pro databÃ¡zi
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'backend'))

try:
    from api.database import get_prisma_client
    DATABASE_AVAILABLE = True
except ImportError:
    DATABASE_AVAILABLE = False

logger = logging.getLogger(__name__)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

async def publish_assistant(input_data: Dict[str, Any], assistant_id: Optional[str] = None) -> str:
    """PÅ™ipravuje content pro publikaci a zajiÅ¡Å¥uje finÃ¡lnÃ­ formÃ¡tovÃ¡nÃ­."""
    
    logger.info(f"ğŸš€ PublishAssistant pÅ™ipravuje k publikaci: {len(str(input_data))} znakÅ¯")
    logger.info(f"ğŸ” PublishAssistant input_data keys: {list(input_data.keys()) if isinstance(input_data, dict) else 'Not a dict'}")
    
    # ğŸ”§ OPRAVA: Inicializace OpenAI client
    from utils.api_keys import get_api_key
    
    api_key = get_api_key("openai")
    if not api_key:
        logger.error("âŒ OpenAI API klÃ­Ä nenÃ­ k dispozici pro PublishAssistant")
        return "Chyba: OpenAI API klÃ­Ä nenÃ­ k dispozici"
        
    client = OpenAI(api_key=api_key)
    
    default_params = {
        "model": "gpt-4o",
        "temperature": 0.3,  # NÃ­zkÃ¡ pro konzistentnÃ­ formÃ¡tovÃ¡nÃ­
        "top_p": 0.9,
        "max_tokens": 2000,
        "system_prompt": "Jsi specialist na finÃ¡lnÃ­ pÅ™Ã­pravu obsahu k publikaci. ZajiÅ¡Å¥ujeÅ¡ sprÃ¡vnÃ© formÃ¡tovÃ¡nÃ­, strukturu a publikaÄnÃ­ metadata."
    }
    
    if assistant_id and DATABASE_AVAILABLE:
        try:
            prisma = await get_prisma_client()
            assistant = await prisma.assistant.find_unique(where={"id": assistant_id})
            if assistant:
                default_params.update({
                    "model": assistant.model or default_params["model"],
                    "temperature": assistant.temperature if assistant.temperature is not None else default_params["temperature"],
                    "top_p": assistant.top_p if assistant.top_p is not None else default_params["top_p"],
                    "max_tokens": assistant.max_tokens or default_params["max_tokens"],
                    "system_prompt": assistant.system_prompt or default_params["system_prompt"]
                })
        except Exception as e:
            logger.error(f"âŒ Chyba pÅ™i naÄÃ­tÃ¡nÃ­ parametrÅ¯: {e}")
    
    # ğŸ”§ OPRAVA: SprÃ¡vnÃ½ parsing vÃ½stupÅ¯ od asistentÅ¯ 
    # Input_data obsahuje vÅ¡echny vÃ½stupy z pipeline jako {assistant_name: {output: "...", metadata: {...}}}
    
    logger.info(f"ğŸ” DEBUG: input_data type: {type(input_data)}")
    logger.info(f"ğŸ” DEBUG: input_data sample: {str(input_data)[:500]}...")
    
    # Extrahuj vÃ½stupy od jednotlivÃ½ch asistentÅ¯
    seo_output = ""
    humanized_content = ""
    qa_results = {}
    multimedia_data = ""
    
    if isinstance(input_data, dict):
        # Hledej vÃ½stupy od klÃ­ÄovÃ½ch asistentÅ¯
        for assistant_name, assistant_data in input_data.items():
            if isinstance(assistant_data, dict) and "output" in assistant_data:
                output = assistant_data["output"]
                
                if "seo" in assistant_name.lower():
                    seo_output = output
                    logger.info(f"âœ… Nalezen SEO output: {len(output)} znakÅ¯")
                elif "humanizer" in assistant_name.lower():
                    humanized_content = output
                    logger.info(f"âœ… Nalezen Humanizer output: {len(output)} znakÅ¯")
                elif "qa" in assistant_name.lower():
                    # QA mÅ¯Å¾e bÃ½t JSON string
                    try:
                        qa_results = json.loads(output) if isinstance(output, str) else output
                        logger.info(f"âœ… Nalezen QA output: {len(str(qa_results))} znakÅ¯")
                    except:
                        qa_results = {"raw": output}
                elif "multimedia" in assistant_name.lower():
                    multimedia_data = output
                    logger.info(f"âœ… Nalezen Multimedia output: {len(output)} znakÅ¯")
    
    # Priorita pro obsah: SEO > Humanized > nejvÄ›tÅ¡Ã­ dostupnÃ½ obsah
    content = ""
    if seo_output and len(seo_output) > 100:
        content = seo_output
        logger.info("ğŸ“„ PouÅ¾Ã­vÃ¡m SEO optimalizovanÃ½ obsah")
    elif humanized_content and len(humanized_content) > 100:
        content = humanized_content  
        logger.info("ğŸ“„ PouÅ¾Ã­vÃ¡m humanizovanÃ½ obsah")
    else:
        # Fallback - hledej nejvÄ›tÅ¡Ã­ textovÃ½ obsah
        logger.warning("âš ï¸ HledÃ¡m fallback obsah...")
        if isinstance(input_data, dict):
            for key, value in input_data.items():
                if isinstance(value, dict) and "output" in value:
                    output = value["output"]
                    if isinstance(output, str) and len(output) > len(content):
                        content = output
                        logger.info(f"ğŸ“„ Fallback obsah z {key}: {len(content)} znakÅ¯")
    
    if not content:
        content = json.dumps(input_data, ensure_ascii=False)
    
    prompt = f"""
PÅ™iprav nÃ¡sledujÃ­cÃ­ obsah k finÃ¡lnÃ­ publikaci:

OBSAH:
{content}

QA VÃSLEDKY:
{json.dumps(qa_results, ensure_ascii=False) if qa_results else "Å½Ã¡dnÃ© QA vÃ½sledky"}

POÅ½ADAVKY NA PUBLIKAÄŒNÃ FORMÃT:
1. Zkontroluj a oprav vÅ¡echny HTML tagy
2. PÅ™idej chybÄ›jÃ­cÃ­ meta tagy (description, keywords)
3. Optimalizuj strukturu nadpisÅ¯ (H1, H2, H3)
4. PÅ™idej Open Graph meta tagy pro social media
5. Zkontroluj responsive elementy
6. PÅ™idej schema.org markup kde je vhodnÃ©
7. FinÃ¡lnÃ­ kontrola pÅ™ed publikacÃ­

VÃSTUP:
VraÅ¥ pouze finÃ¡lnÃ­ HTML obsah pÅ™ipravenÃ½ k publikaci na web.
Obsah musÃ­ bÃ½t kompletnÃ­, validnÃ­ a optimalizovanÃ½.
    """
    
    try:
        response = client.chat.completions.create(
            model=default_params["model"],
            messages=[
                {"role": "system", "content": default_params["system_prompt"]},
                {"role": "user", "content": prompt}
            ],
            temperature=default_params["temperature"],
            top_p=default_params["top_p"],
            max_tokens=default_params["max_tokens"]
        )
        
        published_content = response.choices[0].message.content.strip()
        logger.info(f"âœ… Content pÅ™ipraven k publikaci: {len(published_content)} znakÅ¯")
        
        return published_content
        
    except Exception as e:
        logger.error(f"âŒ Chyba pÅ™i pÅ™Ã­pravÄ› k publikaci: {e}")
        
        # Fallback - zÃ¡kladnÃ­ publikaÄnÃ­ formÃ¡t
        return _fallback_publish_format(content, input_data)

def _fallback_publish_format(content: str, input_data: Dict[str, Any]) -> str:
    """Fallback formÃ¡tovÃ¡nÃ­ kdyÅ¾ OpenAI API nenÃ­ dostupnÃ©"""
    logger.info(f"ğŸ”„ PouÅ¾Ã­vÃ¡m fallback publikaÄnÃ­ formÃ¡t")
    
    # ZÃ¡kladnÃ­ HTML struktura
    if not content.startswith('<!DOCTYPE') and not content.startswith('<html'):
        formatted_content = f"""<!DOCTYPE html>
<html lang="cs">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="KvalitnÃ­ obsah pÅ™ipravenÃ½ k publikaci">
    <title>ÄŒlÃ¡nek - {input_data.get('topic', 'NeznÃ¡mÃ© tÃ©ma')}</title>
</head>
<body>
    <article>
        {content}
    </article>
    
    <footer>
        <p><em>PublikovÃ¡no: {datetime.now().strftime('%d.%m.%Y')}</em></p>
        <p><em>Obsah byl pÅ™ipraven automaticky v fallback mÃ³du.</em></p>
    </footer>
</body>
</html>"""
    else:
        formatted_content = content
    
    return formatted_content

def publish_assistant_sync(input_data: Dict[str, Any], assistant_id: Optional[str] = None) -> str:
    import asyncio
    return asyncio.run(publish_assistant(input_data, assistant_id))