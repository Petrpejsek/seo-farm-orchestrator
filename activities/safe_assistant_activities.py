"""
ğŸ›¡ï¸ BEZPEÄŒNÃ‰ ASSISTANT AKTIVITY PRO PRODUKÄŒNÃ PROSTÅ˜EDÃ
StabilnÃ­ verze assistant aktivit s kompletnÃ­m error handlingem.
"""

import json
import asyncio
from typing import Dict, Any, Optional, List
from datetime import datetime
from temporalio import activity

# NaÅ¡e novÃ© bezpeÄnÃ© moduly
from activity_wrappers import safe_activity, validate_activity_input, safe_llm_call
from logger import get_logger, log_llm_request, log_llm_response
from config import get_llm_config, get_activity_config

# OriginÃ¡lnÃ­ zÃ¡vislosti
from backend.llm_clients.factory import LLMClientFactory
from prisma import Prisma

logger = get_logger(__name__)

@safe_activity(name="load_assistants_from_database", timeout_seconds=60)
async def load_assistants_from_database(project_id: str) -> Dict[str, Any]:
    """
    BezpeÄnÄ› naÄte asistenty z databÃ¡ze pro danÃ½ projekt.
    
    Args:
        project_id: ID projektu
        
    Returns:
        Dict s naÄtenÃ½mi asistenty
    """
    validate_activity_input({"project_id": project_id}, ["project_id"])
    
    if not project_id or not project_id.strip():
        raise ValueError("Project ID nesmÃ­ bÃ½t prÃ¡zdnÃ©")
    
    db = None
    try:
        db = Prisma()
        await db.connect()
        
        # NaÄtenÃ­ pouze aktivnÃ­ch asistentÅ¯ (bez order_by - seÅ™adÃ­me v Pythonu)
        assistants = await db.assistant.find_many(
            where={"projectId": project_id, "active": True}
        )
        
        logger.info(f"ğŸ“Š NaÄteno {len(assistants)} asistentÅ¯ z databÃ¡ze pro projekt {project_id}")
        
        # SeÅ™azenÃ­ podle order pole v Pythonu
        assistants = sorted(assistants, key=lambda x: x.order if x.order is not None else 0)
        
        if not assistants:
            logger.warning(f"âš ï¸ Å½Ã¡dnÃ­ asistenti nebyli nalezeni pro projekt {project_id}")
            return {
                "status": "warning",
                "assistants": [],
                "count": 0,
                "message": f"Å½Ã¡dnÃ­ asistenti pro projekt {project_id}"
            }
        
        # Validace asistentÅ¯
        valid_assistants = []
        for assistant in assistants:
            if not assistant.name or not assistant.name.strip():
                logger.error(f"âŒ Asistent {assistant.id} mÃ¡ prÃ¡zdnÃ½ nÃ¡zev - pÅ™eskakuji")
                continue
            
            if not assistant.functionKey:
                logger.error(f"âŒ Asistent {assistant.name} nemÃ¡ functionKey - pÅ™eskakuji")
                continue
                
            valid_assistants.append({
                "id": assistant.id,
                "name": assistant.name,
                "function_key": assistant.functionKey,
                "system_prompt": assistant.system_prompt or "",
                "model_provider": assistant.model_provider or "openai", 
                "model": assistant.model or "gpt-3.5-turbo",
                "temperature": assistant.temperature or 0.7,
                "max_tokens": assistant.max_tokens,
                "order": assistant.order or 0
            })
        
        logger.info(f"âœ… NaÄteno {len(valid_assistants)} validnÃ­ch asistentÅ¯ z {len(assistants)} celkem")
        
        return {
            "status": "completed",
            "assistants": valid_assistants,
            "count": len(valid_assistants),
            "project_id": project_id
        }
        
    finally:
        if db:
            await db.disconnect()

@safe_activity(name="execute_assistant", timeout_seconds=600, heartbeat_interval=30)
async def execute_assistant(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    BezpeÄnÄ› spustÃ­ jednoho asistenta s LLM volÃ¡nÃ­m.
    
    Args:
        args: Dictionary obsahujÃ­cÃ­:
            - assistant_config: Konfigurace asistenta
            - topic: TÃ©ma/vstup pro asistenta
            - current_date: AktuÃ¡lnÃ­ datum (optional)
            - previous_outputs: VÃ½stupy pÅ™edchozÃ­ch asistentÅ¯ (optional)
        
    Returns:
        Dict s vÃ½stupem asistenta
    """
    # Extrakce argumentÅ¯ z args dictionary
    assistant_config = args.get("assistant_config")
    topic = args.get("topic")
    current_date = args.get("current_date")
    previous_outputs = args.get("previous_outputs", {})
    
    validate_activity_input(
        {"assistant_config": assistant_config, "topic": topic},
        ["assistant_config", "topic"]
    )
    
    assistant_name = assistant_config.get("name", "Unknown")
    function_key = assistant_config.get("function_key", "unknown")
    
    logger.info(f"ğŸš€ SpouÅ¡tÃ­m asistenta: {assistant_name} ({function_key})")
    logger.info(f"ğŸ” DEBUG: function_key='{function_key}', type={type(function_key)}, len={len(str(function_key))}")
    logger.info(f"ğŸ” ASSISTANT_CONFIG KEYS: {list(assistant_config.keys())}")
    if "Publish" in assistant_name:
        logger.info(f"ğŸ” PUBLISH_ASSISTANT_CONFIG_FULL: {assistant_config}")
    
    # Validace konfigurace
    required_fields = ["name", "function_key", "model_provider", "model"]
    missing_fields = [field for field in required_fields if not assistant_config.get(field)]
    if missing_fields:
        raise ValueError(f"ChybÃ­ povinnÃ¡ pole v assistant_config: {missing_fields}")
    
    # PÅ™Ã­prava vstupnÃ­ch dat
    if topic is None:
        raise ValueError("Topic nesmÃ­ bÃ½t None")
    
    # ğŸ”§ OPRAVA: PublishScript deterministickÃ½ - bez AI!
    logger.info(f"ğŸ” KONTROLA: function_key == 'publish_script' ? {function_key == 'publish_script'}")
    if function_key == "publish_script":
        # ğŸ”§ DETERMINISTICKÃ PUBLISH SCRIPT - Å¾Ã¡dnÃ© LLM!
        logger.info(f"ğŸ”§ SPOUÅ TÃM DETERMINISTICKÃ PUBLISH SCRIPT")
        
        # Zajistit dictionary format pro publish_activity
        if not isinstance(topic, dict):
            logger.warning(f"âš ï¸ PublishScript oÄekÃ¡vÃ¡ dict, dostal {type(topic).__name__}")
            topic = {"content": str(topic)}
        
        logger.info(f"ğŸ¯ PublishScript dostÃ¡vÃ¡ dictionary s {len(topic)} klÃ­Äi")
        
        # PÅ˜ÃMÃ‰ VOLÃNÃ publish_activity mÃ­sto LLM
        from activities.publish_activity import publish_activity
        import asyncio
        
        try:
            # SestavenÃ­ dat pro publish_activity
            # PublishScript potÅ™ebuje vÅ¡echna pipeline data, ne jen vÃ½stup ImageRenderer
            final_outputs = previous_outputs.copy() if previous_outputs else {}
            if topic and isinstance(topic, dict):
                # PÅ™idat ImageRenderer vÃ½stup do pipeline dat
                final_outputs["image_renderer_assistant_output"] = topic
            
            publish_data = {
                "assistant_config": assistant_config,
                "topic": final_outputs,  # VÅ¡echna pipeline data mÃ­sto jen ImageRenderer vÃ½stupu
                "current_date": current_date or datetime.now().isoformat(),
                "previous_outputs": final_outputs
            }
            
            logger.info(f"ğŸ”§ VolÃ¡m publish_activity s {len(final_outputs)} komponenty")
            
            # PÅ™Ã­mÃ© async volÃ¡nÃ­ publish_activity (jiÅ¾ jsme v async kontextu)
            result = await publish_activity(publish_data)
            
            logger.info(f"âœ… PublishScript dokonÄen: {len(str(result))} znakÅ¯")
            return result
            
        except Exception as e:
            logger.error(f"âŒ PublishScript selhal: {e}")
            raise Exception(f"DeterministickÃ½ PublishScript selhal: {e}")
        
        # Tohle se uÅ¾ nikdy nespustÃ­, ale ponechÃ¡m pro jistotu
        user_message = "DETERMINISTICKY_SCRIPT - tento text se nepouÅ¾Ã­vÃ¡"
        
    else:
        # OstatnÃ­ asistenti potÅ™ebujÃ­ string
        if isinstance(topic, dict):
            # Pokud je dict, vezmi "output" klÃ­Ä nebo celÃ½ JSON
            import json
            topic = topic.get("output", json.dumps(topic, ensure_ascii=False))
            logger.info(f"ğŸ”„ Topic je dict - pÅ™evÃ¡dÃ­m na string ({len(str(topic))} chars)")
        elif not isinstance(topic, str):
            topic = str(topic)
            logger.info(f"ğŸ”„ Topic nenÃ­ string - pÅ™evÃ¡dÃ­m ({type(topic).__name__} -> str)")
        
        # Kontrola prÃ¡zdnosti pouze pro string topics
        if isinstance(topic, str) and not topic.strip():
            logger.warning(f"âš ï¸ PrÃ¡zdnÃ½ topic pro {assistant_name} - pokraÄuji")
            topic = ""
        
        # PÅ™Ã­prava user message s datem
        user_message = topic
        if current_date:
            user_message = f"ğŸ“… AktuÃ¡lnÃ­ datum: {current_date}\n\n{topic}"
    
    # SpeciÃ¡lnÃ­ handling pro QAAssistant - analyzuj obsah ze VÅ ECH pÅ™edchozÃ­ch asistentÅ¯
    if function_key == "qa_assistant" and previous_outputs:
        # ğŸ” DETAILNÃ DEBUGGING - co QA asistent skuteÄnÄ› dostÃ¡vÃ¡
        logger.info(f"ğŸ” QA ASISTENT DEBUGGING:")
        logger.info(f"   ğŸ“¦ DostÃ¡vÃ¡ {len(previous_outputs)} klÃ­ÄÅ¯ v previous_outputs:")
        for key, value in previous_outputs.items():
            value_length = len(str(value)) if value else 0
            logger.info(f"      ğŸ—ï¸ {key}: {value_length} znakÅ¯")
        
        # ShromaÅ¾di obsah k analÃ½ze ze VÅ ECH klÃ­ÄovÃ½ch asistentÅ¯
        content_to_analyze = []
        
        # Definice VÅ ECH asistentÅ¯ co QA potÅ™ebuje analyzovat (order 1-7, pÅ™ed QA v DB poÅ™adÃ­)
        assistant_priorities = [
            # V poÅ™adÃ­ podle database order:
            ("brief_assistant_output", "Brief Assistant", 2000),           # order 1
            ("research_assistant_output", "Research Assistant", 3000),      # order 2  
            ("fact_validator_assistant_output", "Fact Validator Assistant", 2000), # order 3
            ("draft_assistant_output", "Draft Assistant", 5000),            # order 4
            ("humanizer_assistant_output", "Humanizer Assistant", 5000),    # order 5
            ("seo_assistant_output", "SEO Assistant", 2000),                # order 6
            ("multimedia_assistant_output", "Multimedia Assistant", 1500),  # order 7
            # QA asistent mÃ¡ order 8 (TENTO asistent)
            # ImageRenderer mÃ¡ order 9 (po QA)
        ]
        
        # Zpracuj vÅ¡echny dostupnÃ© asistenty
        missing_assistants = []
        empty_assistants = []
        
        for output_key, assistant_name, max_chars in assistant_priorities:
            if output_key in previous_outputs:
                output = previous_outputs[output_key]
                if output and str(output).strip():
                    output_str = str(output)
                    if len(output_str) > max_chars:
                        output_preview = output_str[:max_chars] + f"...\n[ZKRÃCENO z {len(output_str)} znakÅ¯]"
                    else:
                        output_preview = output_str
                    content_to_analyze.append(f"=== OBSAH K ANALÃZE Z {assistant_name.upper()} ===\n{output_preview}")
                    logger.info(f"âœ… QA pÅ™idal {assistant_name}: {len(output_str)} znakÅ¯ (zkrÃ¡ceno na {min(len(output_str), max_chars)})")
                else:
                    empty_assistants.append(f"{assistant_name} ({output_key})")
                    logger.warning(f"âš ï¸ QA asistent mÃ¡ prÃ¡zdnÃ½ vÃ½stup z {assistant_name} ({output_key})")
            else:
                missing_assistants.append(f"{assistant_name} ({output_key})")
                logger.warning(f"âŒ QA asistent nemÃ¡ klÃ­Ä {output_key} v previous_outputs")
        
        # ğŸ” DETAILNÃ ANALÃZA CHYBÄšJÃCÃCH DAT
        if missing_assistants:
            logger.error(f"âŒ QA asistent: CHYBÄšJÃCÃ KLÃÄŒE v previous_outputs: {', '.join(missing_assistants)}")
        if empty_assistants:
            logger.warning(f"âš ï¸ QA asistent: PRÃZDNÃ‰ VÃSTUPY z asistentÅ¯: {', '.join(empty_assistants)}")
        
        if content_to_analyze:
            # VytvoÅ™ message pro QA analÃ½zu se VÅ EMI daty
            analysis_content = "\n\n".join(content_to_analyze)
            user_message = f"ğŸ“… AktuÃ¡lnÃ­ datum: {current_date}\n\nPROVEÄ KOMPLEXNÃ QA KONTROLU tohoto obsahu ze vÅ¡ech asistentÅ¯ a vraÅ¥ strukturovanou analÃ½zu ve formÃ¡tu JSON:\n\n{analysis_content}"
            logger.info(f"ğŸ” QA asistent dostÃ¡vÃ¡ kompletnÃ­ obsah k analÃ½ze: {len(analysis_content)} znakÅ¯ z {len(content_to_analyze)} asistentÅ¯")
            logger.info(f"ğŸ“Š QA STATISTIKY: ÃšspÄ›Å¡nÃ½ch {len(content_to_analyze)}, PrÃ¡zdnÃ½ch {len(empty_assistants)}, ChybÄ›jÃ­cÃ­ch {len(missing_assistants)}")
        else:
            error_msg = f"QA asistent nenaÅ¡el obsah k analÃ½ze z Å¾Ã¡dnÃ©ho pÅ™edchozÃ­ho asistenta! ChybÄ›jÃ­cÃ­: {missing_assistants}, PrÃ¡zdnÃ©: {empty_assistants}"
            logger.error(f"âŒ {error_msg}")
            raise ValueError(error_msg)
    
    # SpeciÃ¡lnÃ­ handling pro ImageRendererAssistant - pouÅ¾ij data od MultimediaAssistant
    elif function_key == "image_renderer_assistant" and previous_outputs:
        multimedia_output = previous_outputs.get("multimedia_assistant_output")
        if multimedia_output:
            try:
                # MultimediaAssistant vracÃ­ markdown JSON blok
                if isinstance(multimedia_output, str):
                    import json
                    # Extrakce JSON z markdown bloku (```json\n...\n```)
                    if "```json" in multimedia_output:
                        json_start = multimedia_output.find("```json") + 7
                        json_end = multimedia_output.find("```", json_start)
                        if json_end != -1:
                            json_str = multimedia_output[json_start:json_end].strip()
                            image_prompts = json.loads(json_str)
                        else:
                            raise ValueError("NepoaÅ™ilo se najÃ­t ukonÄenÃ­ JSON bloku v MultimediaAssistant vÃ½stupu")
                    else:
                        raise ValueError("âŒ MultimediaAssistant vÃ½stup nenÃ­ validnÃ­ JSON struktura - publish nemÅ¯Å¾e pokraÄovat")
                else:
                    # NativnÃ­ objekt
                    image_prompts = multimedia_output
                
                # ğŸ”§ OPRAVA: MultimediaAssistant vracÃ­ {primary_visuals: [...], optional_visuals: [...]}
                # PÅ™evod na formÃ¡t pro ImageRenderer: pole s image_prompt poloÅ¾kami
                visuals_data = []
                if "primary_visuals" in image_prompts:
                    visuals_data.extend(image_prompts["primary_visuals"])
                if "optional_visuals" in image_prompts:
                    visuals_data.extend(image_prompts["optional_visuals"])
                
                # ğŸ¯ PÅ˜EVOD NA FORMAT PRO IMAGERENDERER
                formatted_prompts = []
                for visual in visuals_data:
                    if "image_prompt" in visual:
                        formatted_prompts.append(visual["image_prompt"])
                
                logger.info(f"ğŸ¨ ImageRenderer input: {len(formatted_prompts)} image prompts z MultimediaAssistant")
                
                # PÅ™edej jako JSON string pro ImageRenderer
                if formatted_prompts:
                    # VytvoÅ™ JSON se seznamem promptÅ¯
                    user_message = json.dumps(formatted_prompts, ensure_ascii=False)
                else:
                    raise ValueError("âŒ MultimediaAssistant neposkytl poÅ¾adovanÃ¡ data pro ImageRenderer - publish nemÅ¯Å¾e pokraÄovat")
                
            except Exception as e:
                logger.error(f"âŒ Chyba pÅ™i parsovÃ¡nÃ­ MultimediaAssistant output: {e}")
                raise ValueError(f"âŒ MultimediaAssistant parsovÃ¡nÃ­ selhalo: {str(e)} - publish nemÅ¯Å¾e pokraÄovat")
        else:
            raise ValueError("ImageRenderer neobdrÅ¾el data od MultimediaAssistant")
    
    # ğŸ”§ PÅ˜IDÃNO: SpeciÃ¡lnÃ­ handling pro PublishAssistant - oÄekÃ¡vÃ¡ dictionary input
    elif function_key == "publish_script":
        if isinstance(topic, dict):
            # PublishAssistant dostÃ¡vÃ¡ vÅ¡echny komponenty jako dictionary
            user_message = topic  # PÅ™edej celÃ½ dictionary
            logger.info(f"ğŸ¯ PublishAssistant input: dictionary s {len(topic)} komponentami")
        else:
            raise ValueError(f"âŒ PublishScript oÄekÃ¡vÃ¡ dictionary input, ale dostal {type(topic)} - publish nemÅ¯Å¾e pokraÄovat")
    
    else:
        # ğŸ”§ OSTATNÃ ASISTENTI: standardnÃ­ text input s datem  
        if current_date:
            user_message = f"ğŸ“… AktuÃ¡lnÃ­ datum: {current_date}\n\n{topic}"
        else:
            user_message = str(topic)
        
        if len(str(topic)) > 100:
            logger.info(f"ğŸ“ {assistant_name} input: {len(str(topic))} chars")
    
    # ZÃ­skÃ¡nÃ­ LLM konfigurace
    llm_config = get_llm_config()
    model_provider = assistant_config.get("model_provider")
    model = assistant_config.get("model")
    temperature = assistant_config.get("temperature")
    max_tokens = assistant_config.get("max_tokens")
    
    # ğŸš« Å½ÃDNÃ‰ DEFAULTY! VÅ¡echny hodnoty musÃ­ bÃ½t explicitnÄ› nastavenÃ© v databÃ¡zi!
    if not model_provider:
        raise Exception(f"âŒ CHYBÃ model_provider pro asistenta {assistant_config.get('name', 'unknown')}!")
    if not model:
        raise Exception(f"âŒ CHYBÃ model pro asistenta {assistant_config.get('name', 'unknown')}!")
    if temperature is None:
        raise Exception(f"âŒ CHYBÃ temperature pro asistenta {assistant_config.get('name', 'unknown')}!")
    if max_tokens is None:
        raise Exception(f"âŒ CHYBÃ max_tokens pro asistenta {assistant_config.get('name', 'unknown')}!")
    system_prompt = assistant_config.get("system_prompt")
    
    # ğŸš« Å½ÃDNÃ‰ FALLBACKY! Pokud system_prompt nenÃ­ v databÃ¡zi, SELHAT!
    if not system_prompt or not system_prompt.strip():
        raise Exception(f"âŒ Å½ÃDNÃ SYSTEM PROMPT pro asistenta {assistant_config.get('name', 'unknown')}! MusÃ­ bÃ½t v databÃ¡zi!")
    
    # SpeciÃ¡lnÃ­ handling pro -1 (unlimited)
    if max_tokens == -1:
        max_tokens = None
    
    logger.info(f"ğŸ¤– LLM konfigurace: {model_provider}/{model} (temp: {temperature}, tokens: {max_tokens or 'unlimited'})")
    
    # VytvoÅ™enÃ­ LLM clienta
    try:
        llm_client = LLMClientFactory.create_client(model_provider)
        log_llm_request(logger, model_provider, model, max_tokens)
        
        # BezpeÄnÃ© LLM volÃ¡nÃ­ - rozpoznÃ¡nÃ­ typu modelu
        start_time = datetime.now()
        
        # Detekce image modelÅ¯ (DALL-E + Google Imagen) - SPECIÃLNÃ HANDLING PRO IMAGERENDERER
        image_models = ["dall-e-3", "dall-e-2", "dall-e", "imagen-4", "imagen-3", "imagen"]
        is_image_model = any(img_model in model.lower() for img_model in image_models)
        
        if is_image_model and function_key == "image_renderer_assistant":
            # ğŸ¯ SPECIÃLNÃ LOGIKA PRO IMAGERENDERER - VYGENERUJ VÅ ECHNY OBRÃZKY
            logger.info(f"ğŸ¨ IMAGERENDERER SPECIÃLNÃ HANDLING: model={model}")
            
            try:
                # Extrahuj image_prompts z MultimediaAssistant vÃ½stupu
                image_prompts = await _extract_image_prompts_from_input(user_message)
                logger.info(f"ğŸ” Nalezeno {len(image_prompts)} image_prompts")
                
                if not image_prompts:
                    logger.warning("âš ï¸ ImageRenderer: Å½Ã¡dnÃ© image_prompts nalezeny v inputu")
                    # VraÅ¥ prÃ¡zdnÃ½ ale validnÃ­ vÃ½sledek mÃ­sto exception
                    final_result = {
                        "images": [],
                        "successful_count": 0,
                        "total_count": 0,
                        "model": model,
                        "config": {"provider": model_provider},
                        "warning": "No image_prompts found in input"
                    }
                    
                    return {
                        "status": "completed", 
                        "output": final_result,  # â† NATIVNÃ OBJEKT, NE STRING!
                        "assistant": assistant_name,
                        "function_key": function_key,
                        "provider": model_provider,
                        "model": model,
                        "duration": (datetime.now() - start_time).total_seconds(),
                        "input_length": len(user_message),
                        "output_length": len(str(final_result))
                    }
                
                logger.info(f"ğŸ¨ Nalezeno {len(image_prompts)} image_prompts k vygenerovÃ¡nÃ­")
                
                # Vygeneruj obrÃ¡zek pro kaÅ¾dÃ½ prompt
                generated_images = []
                
                for i, prompt in enumerate(image_prompts):
                    logger.info(f"ğŸ¨ Generuji obrÃ¡zek {i+1}/{len(image_prompts)}: {prompt[:100]}...")
                    
                    # PouÅ¾ij safe_llm_call pro image generation
                    try:
                        logger.info(f"ğŸ¤– IMAGE generace pro prompt {i+1}: {model_provider}/{model}")
                        
                        llm_result = await safe_llm_call(
                            llm_func=llm_client.image_generation,
                            provider=model_provider,
                            model=model,
                            prompt=prompt,
                            size="1024x1024",
                            quality="standard",
                            style="vivid",
                            max_retries=3
                        )
                        
                        if not llm_result or "content" not in llm_result:
                            raise Exception(f"Image generation vrÃ¡til nevalidnÃ­ response: {llm_result}")
                            
                        logger.info(f"âœ… IMAGE ÃºspÄ›ch pro prompt {i+1}: {model_provider}/{model}")
                        
                    except Exception as e:
                        logger.error(f"âŒ Image generation selhal pro prompt {i+1}: {str(e)}")
                        # PÅ™idej chybnÃ½ obrÃ¡zek mÃ­sto exception
                        generated_images.append({
                            "url": "",
                            "prompt": prompt,
                            "status": "failed",
                            "error": f"Image generation failed: {str(e)}"
                        })
                        continue
                    
                    # Extrahuj URL z response
                    image_url = await _extract_url_from_image_response(llm_result)
                    if not image_url:
                        logger.warning(f"âš ï¸ Å½Ã¡dnÃ¡ URL nalezena v image response pro prompt {i+1}")
                        generated_images.append({
                            "url": "",
                            "prompt": prompt,
                            "status": "failed",
                            "error": "No URL found in image response"
                        })
                        continue
                    
                    generated_images.append({
                        "url": image_url,
                        "prompt": prompt,
                        "status": "completed"
                    })
                    
                    logger.info(f"âœ… ObrÃ¡zek {i+1} vygenerovÃ¡n: {image_url[:100]}...")
                
                # VytvoÅ™ finÃ¡lnÃ­ output jako NATIVNÃ OBJEKT (ne string!)
                # I kdyÅ¾ nÄ›kterÃ© obrÃ¡zky selhaly, vraÅ¥ co se podaÅ™ilo vygenerovat
                successful_images = [img for img in generated_images if img["status"] == "completed"]
                
                final_result = {
                    "images": generated_images,  # Zahrnuj vÅ¡echny obrÃ¡zky (i chybnÃ©)
                    "successful_count": len(successful_images),
                    "total_count": len(image_prompts),
                    "model": model,
                    "config": {"provider": model_provider}
                }
                
                logger.info(f"ğŸ‰ ImageRenderer HOTOVO: {len(generated_images)} obrÃ¡zkÅ¯ vygenerovÃ¡no!")
                
                # VraÅ¥ jako nativnÃ­ objekt pro workflow
                return {
                    "status": "completed", 
                    "output": final_result,  # â† NATIVNÃ OBJEKT, NE STRING!
                    "assistant": assistant_name,
                    "function_key": function_key,
                    "provider": model_provider,
                    "model": model,
                    "duration": (datetime.now() - start_time).total_seconds(),
                    "input_length": len(user_message),
                    "output_length": len(str(final_result))
                }
            
            except Exception as e:
                logger.error(f"âŒ CHYBA v ImageRenderer speciÃ¡lnÃ­ logice: {e}")
                # VraÅ¥ chybovÃ½ vÃ½sledek jako nativnÃ­ objekt - NIKDY nepokraÄuj do elif is_image_model
                error_result = {
                    "images": [],
                    "successful_count": 0,
                    "total_count": 0,
                    "model": model,
                    "config": {"provider": model_provider},
                    "error": f"ImageRenderer logic failed: {str(e)}"
                }
                
                return {
                    "status": "completed", 
                    "output": error_result,  # â† NATIVNÃ OBJEKT i pÅ™i chybÄ›!
                    "assistant": assistant_name,
                    "function_key": function_key,
                    "provider": model_provider,
                    "model": model,
                    "duration": (datetime.now() - start_time).total_seconds(),
                    "input_length": len(user_message),
                    "output_length": len(str(error_result))
                }
            
        elif is_image_model:
            # Pro ostatnÃ­ image modely (pokud nÄ›jakÃ© jsou)
            logger.info(f"ğŸ¨ OBECNÃ IMAGE GENERATION: model={model}")
            
            # PouÅ¾ij safe_llm_call pro image generation
            llm_result = await safe_llm_call(
                llm_func=llm_client.image_generation,
                provider=model_provider,
                model=model,
                prompt=user_message,
                size="1024x1024",
                quality="standard",
                style="vivid",
                max_retries=3
            )
            
            if not llm_result or "content" not in llm_result:
                raise Exception(f"Image generation selhalo - nevalidnÃ­ response: {llm_result}")
        else:
            # Pro text modely pouÅ¾Ã­vÃ¡me chat_completion API
            llm_result = await safe_llm_call(
                llm_func=llm_client.chat_completion,
                provider=model_provider,
                model=model,
                system_prompt=system_prompt,
                user_message=user_message,
                temperature=temperature,
                max_tokens=max_tokens,
                max_retries=3
            )
        
        duration = (datetime.now() - start_time).total_seconds()
        
        # Extraha odpovÄ›Ä
        content = llm_result.get("content", "")
        if not content:
            raise ValueError(f"LLM vrÃ¡til prÃ¡zdnÃ½ content: {llm_result}")
        
        log_llm_response(logger, model_provider, len(content), duration)
        
        # SpeciÃ¡lnÃ­ handling pro konkrÃ©tnÃ­ asistenty (kromÄ› ImageRenderer kterÃ½ mÃ¡ vlastnÃ­ handling vÃ½Å¡e)
        logger.info(f"ğŸ”§ PRE-PROCESSING: {function_key} content preview: {content[:100]}...")
        processed_output = await _process_assistant_output(
            function_key, content, assistant_name
        )
        logger.info(f"ğŸ”§ POST-PROCESSING: {function_key} output preview: {processed_output[:100]}...")
        
        return {
            "status": "completed",
            "output": processed_output,
            "assistant": assistant_name,
            "function_key": function_key,
            "provider": model_provider,
            "model": model,
            "duration": duration,
            "input_length": len(user_message),
            "output_length": len(processed_output)
        }
        
    except Exception as e:
        logger.error(f"âŒ LLM volÃ¡nÃ­ selhalo pro {assistant_name}: {str(e)}")
        raise

async def _extract_image_prompts_from_input(user_message: str) -> list:
    """
    Extrahuje image_prompts z vÃ½stupu MultimediaAssistant.
    
    Args:
        user_message: Input pro ImageRenderer (obsahuje output od MultimediaAssistant)
        
    Returns:
        Seznam image_prompts jako List[str]
    """
    import json
    import re
    
    try:
        logger.info(f"ğŸ” Extrakce image_prompts z input: {user_message[:200]}...")
        
        # ZkusÃ­me najÃ­t JSON s image_prompts v user_message
        # MultimediaAssistant vracÃ­ output jako JSON string s image_prompts
        
        # Metoda 1: HledÃ¡me JSON pÅ™Ã­mo
        try:
            # MoÅ¾nÃ¡ je to celÃ© JSON
            data = json.loads(user_message)
            if isinstance(data, list) and len(data) > 0:
                # Je to seznam promptÅ¯ pÅ™Ã­mo
                logger.info(f"ğŸ¨ NaÅ¡el jsem seznam promptÅ¯ pÅ™Ã­mo: {len(data)} items")
                return [str(item) for item in data if str(item).strip()]
            elif isinstance(data, dict):
                # ğŸ”§ NOVÃ LOGIKA: Podpora primary_visuals + optional_visuals struktury
                all_prompts = []
                
                if "image_prompts" in data:
                    prompts = data["image_prompts"]
                    logger.info(f"ğŸ¨ NaÅ¡el jsem image_prompts v dict: {len(prompts)} items")
                    all_prompts.extend([str(prompt) for prompt in prompts if str(prompt).strip()])
                
                # Podpora novÃ© struktury z MultimediaAssistant
                if "primary_visuals" in data:
                    for visual in data["primary_visuals"]:
                        if "image_prompt" in visual:
                            all_prompts.append(visual["image_prompt"])
                    logger.info(f"ğŸ¨ NaÅ¡el jsem {len(data['primary_visuals'])} primary_visuals promptÅ¯")
                
                if "optional_visuals" in data:
                    for visual in data["optional_visuals"]:
                        if "image_prompt" in visual:
                            all_prompts.append(visual["image_prompt"])
                    logger.info(f"ğŸ¨ NaÅ¡el jsem {len(data['optional_visuals'])} optional_visuals promptÅ¯")
                
                if all_prompts:
                    logger.info(f"ğŸ¨ CELKEM nalezeno {len(all_prompts)} image_prompts")
                    return [prompt.strip() for prompt in all_prompts if prompt.strip()]
        except json.JSONDecodeError:
            pass
        
        # Metoda 2: HledÃ¡me JSON uvnitÅ™ textu pomocÃ­ regex
        json_pattern = r'\[\s*"[^"]+(?:"\s*,\s*"[^"]+)*"\s*\]'
        json_matches = re.findall(json_pattern, user_message, re.DOTALL)
        
        for match in json_matches:
            try:
                prompts = json.loads(match)
                if isinstance(prompts, list) and len(prompts) > 0:
                    valid_prompts = [str(prompt) for prompt in prompts if str(prompt).strip()]
                    if valid_prompts:
                        logger.info(f"ğŸ¨ NaÅ¡el jsem {len(valid_prompts)} promptÅ¯ pomocÃ­ regex")
                        return valid_prompts
            except:
                continue
        
        # Metoda 3: HledÃ¡me prompty jako citovanÃ© Å™etÄ›zce
        quote_pattern = r'"([^"]{20,})"'
        quote_matches = re.findall(quote_pattern, user_message)
        
        if quote_matches:
            # Filtruj jen ty co vypadajÃ­ jako image prompty (aspoÅˆ 20 znakÅ¯)
            valid_prompts = [match for match in quote_matches if len(match) >= 20]
            if valid_prompts:
                logger.info(f"ğŸ¨ NaÅ¡el jsem {len(valid_prompts)} promptÅ¯ v uvozovkÃ¡ch")
                return valid_prompts
        
        logger.warning(f"âš ï¸ Å½Ã¡dnÃ© image_prompts nenalezeny v input")
        logger.warning(f"âš ï¸ Input sample: {user_message[:500]}")
        return []
        
    except Exception as e:
        logger.error(f"âŒ Chyba pÅ™i extrakci image_prompts: {e}")
        return []

async def _extract_url_from_image_response(image_response: dict) -> str:
    """
    Extrahuje URL z image API response.
    
    Args:
        image_response: Response z image API
        
    Returns:
        URL obrÃ¡zku nebo None
    """
    try:
        logger.info(f"ğŸ” Extrakce URL z image response: {type(image_response)}")
        
        if isinstance(image_response, dict):
            # Zkus content.url structure
            if "content" in image_response:
                content = image_response["content"]
                if isinstance(content, str):
                    # Je to string s URL - extrahni pomocÃ­ regex
                    import re
                    urls = re.findall(r'https://[^\s\n\)]+', content)
                    if urls:
                        logger.info(f"âœ… URL nalezena v content string: {urls[0][:100]}...")
                        return urls[0]
                elif isinstance(content, list) and len(content) > 0:
                    # Je to seznam s objekty
                    item = content[0]
                    if isinstance(item, dict) and "url" in item:
                        logger.info(f"âœ… URL nalezena v content[0].url: {item['url'][:100]}...")
                        return item["url"]
            
            # Zkus pÅ™Ã­mou URL
            if "url" in image_response:
                logger.info(f"âœ… URL nalezena pÅ™Ã­mo: {image_response['url'][:100]}...")
                return image_response["url"]
        
        logger.warning(f"âš ï¸ Å½Ã¡dnÃ¡ URL nenalezena v image response")
        logger.warning(f"âš ï¸ Response structure: {image_response}")
        return None
        
    except Exception as e:
        logger.error(f"âŒ Chyba pÅ™i extrakci URL: {e}")
        return None

async def _process_assistant_output(
    function_key: str, 
    raw_output: str, 
    assistant_name: str
) -> str:
    """
    Zpracuje vÃ½stup asistenta podle jeho typu.
    ImageRenderer uÅ¾ mÃ¡ vlastnÃ­ speciÃ¡lnÃ­ handling, takÅ¾e tahle funkce se uÅ¾ nepouÅ¾Ã­vÃ¡.
    """
    # Pro vÅ¡echny asistenty vrÃ¡tÃ­me surovÃ½ vÃ½stup
    return raw_output.strip()

# ğŸ—‘ï¸ ODSTRANÄšNO: _process_image_renderer_output - ImageRenderer mÃ¡ teÄ vlastnÃ­ speciÃ¡lnÃ­ handling