"""
ResearchAssistant - Research krok v SEO pipeline
Prov√°d√≠ online research a shroma≈æƒèuje podklady k zadan√©mu t√©matu.
"""

import json
import logging
import os
from typing import Dict, Any, Optional
from openai import OpenAI
from datetime import datetime

# Import pro datab√°zi - mus√≠me ho importovat z backend struktury
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'backend'))

try:
    from api.database import get_prisma_client
    DATABASE_AVAILABLE = True
except ImportError:
    DATABASE_AVAILABLE = False
    print("‚ö†Ô∏è Database import failed - using fallback mode")

logger = logging.getLogger(__name__)

# Inicializace OpenAI klienta
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

async def research_assistant(topic: str, assistant_id: Optional[str] = None) -> Dict[str, Any]:
    """
    Prov√°d√≠ research k zadan√©mu t√©matu a shroma≈æƒèuje podklady.
    
    Args:
        topic (str): T√©ma pro research
        assistant_id (str, optional): ID asistenta pro naƒçten√≠ parametr≈Ø z DB
        
    Returns:
        Dict[str, Any]: JSON s v√Ωsledky research a shrom√°≈ædƒõn√Ωmi podklady
    """
    
    logger.info(f"üîç ResearchAssistant prov√°d√≠ research k t√©matu: {topic}")
    
    # V√Ωchoz√≠ parametry
    default_params = {
        "model": "gpt-4o",
        "temperature": 0.7,
        "top_p": 0.9,
        "max_tokens": 1200,
        "system_prompt": "Jsi expert researcher a content strategist. Tv√Ωm √∫kolem je prov√°dƒõt hloubkov√Ω research k zadan√Ωm t√©mat≈Øm a shroma≈æƒèovat strukturovan√© podklady. Zamƒõ≈ô se na aktu√°ln√≠ trendy, kl√≠ƒçov√° fakta, konkurenƒçn√≠ anal√Ωzu a u≈æiteƒçn√© zdroje informac√≠."
    }
    
    # Pokud m√°me assistant_id, naƒçteme parametry z datab√°ze
    if assistant_id and DATABASE_AVAILABLE:
        try:
            prisma = await get_prisma_client()
            assistant = await prisma.assistant.find_unique(where={"id": assistant_id})
            
            if assistant:
                # Pou≈æijeme parametry z datab√°ze
                params = {
                    "model": assistant.model or default_params["model"],
                    "temperature": assistant.temperature if assistant.temperature is not None else default_params["temperature"],
                    "top_p": assistant.top_p if assistant.top_p is not None else default_params["top_p"],
                    "max_tokens": assistant.max_tokens or default_params["max_tokens"],
                    "system_prompt": assistant.system_prompt or default_params["system_prompt"]
                }
                logger.info(f"‚úÖ Naƒçteny parametry asistenta {assistant_id}")
            else:
                params = default_params
                logger.warning(f"‚ö†Ô∏è Asistent {assistant_id} nenalezen, pou≈æ√≠v√°m v√Ωchoz√≠ parametry")
        except Exception as e:
            logger.error(f"‚ùå Chyba p≈ôi naƒç√≠t√°n√≠ parametr≈Ø asistenta: {e}")
            params = default_params
    else:
        params = default_params
    
    # Prompt pro research
    research_prompt = f"""
Proveƒè hloubkov√Ω research k t√©matu: "{topic}"

Pot≈ôebuji strukturovan√© informace v n√°sleduj√≠c√≠ch oblastech:

1. KL√çƒåOV√Å FAKTA A STATISTIKY
- Aktu√°ln√≠ data, ƒç√≠sla, trendy
- D≈Øle≈æit√© poznatky a insight

2. KONKURENƒåN√ç ANAL√ùZA
- Hlavn√≠ hr√°ƒçi na trhu/v oboru
- Jejich p≈ô√≠stupy a strategie
- Gap v trhu nebo p≈ô√≠le≈æitosti

3. TARGET AUDIENCE ANAL√ùZA  
- Kdo se o t√©ma zaj√≠m√°
- Jak√© jsou jejich pot≈ôeby a pain pointy
- Demografick√© a psychografick√© charakteristiky

4. CONTENT ANGLES A PERSPEKTIVY
- R≈Øzn√© √∫hly pohledu na t√©ma
- Kontroverzn√≠ nebo zaj√≠mav√© aspekty
- P≈ô√≠bƒõhy a case studies

5. ZDROJE A REFERENCE
- Autoritativn√≠ weby a publikace
- Odborn√≠ci v oboru
- Relevantn√≠ studie a v√Ωzkumy

Vra≈• strukturovan√Ω JSON s tƒõmito sekcemi. Zamƒõ≈ô se na praktick√© a actionable informace.
    """
    
    try:
        # Sestaven√≠ zpr√°v pro OpenAI
        messages = []
        if params["system_prompt"]:
            messages.append({"role": "system", "content": params["system_prompt"]})
        messages.append({"role": "user", "content": research_prompt})
        
        # Vol√°n√≠ OpenAI API
        logger.info(f"ü§ñ Vol√°m OpenAI API s modelem {params['model']}")
        response = client.chat.completions.create(
            model=params["model"],
            messages=messages,
            temperature=params["temperature"],
            top_p=params["top_p"],
            max_tokens=params["max_tokens"]
        )
        
        research_result = response.choices[0].message.content.strip()
        logger.info("‚úÖ OpenAI API √∫spƒõ≈°nƒõ vr√°tilo v√Ωsledek")
        
        # Pokus o parsov√°n√≠ JSON z odpovƒõdi
        try:
            # Pokud odpovƒõƒè obsahuje JSON block, extrahujeme ho
            if "```json" in research_result:
                json_start = research_result.find("```json") + 7
                json_end = research_result.find("```", json_start)
                if json_end != -1:
                    json_str = research_result[json_start:json_end].strip()
                    parsed_data = json.loads(json_str)
                else:
                    # Pokud nen√≠ ukonƒçovac√≠ ```, zkus√≠me cel√Ω zbytek
                    json_str = research_result[json_start:].strip()
                    parsed_data = json.loads(json_str)
            else:
                # Pokus√≠me se parsovat celou odpovƒõƒè jako JSON
                parsed_data = json.loads(research_result)
            
            return {
                "research_data": parsed_data,
                "raw_response": research_result,
                "topic": topic,
                "research_status": "success",
                "assistant": "ResearchAssistant",
                "assistant_id": assistant_id,
                "model_used": params["model"],
                "timestamp": datetime.now().isoformat()
            }
            
        except json.JSONDecodeError:
            # Pokud nelze parsovat JSON, vr√°t√≠me raw text ve struktu≈ôe
            logger.warning("‚ö†Ô∏è Nelze parsovat JSON z OpenAI odpovƒõdi, vr√°t√≠m strukturovan√Ω fallback")
            return {
                "research_data": {
                    "key_facts": [research_result[:500] + "..." if len(research_result) > 500 else research_result],
                    "competitive_analysis": "Detailn√≠ anal√Ωza vy≈æaduje dal≈°√≠ zpracov√°n√≠",
                    "target_audience": "Obecn√° audience z√°jemci o " + topic,
                    "content_angles": ["Z√°kladn√≠ p≈ôehled t√©matu", "Praktick√© tipy", "Aktu√°ln√≠ trendy"],
                    "sources": ["OpenAI knowledge base"]
                },
                "raw_response": research_result,
                "topic": topic,
                "research_status": "partial",
                "assistant": "ResearchAssistant",
                "assistant_id": assistant_id,
                "model_used": params["model"],
                "timestamp": datetime.now().isoformat()
            }
            
    except Exception as e:
        logger.error(f"‚ùå Chyba p≈ôi vol√°n√≠ OpenAI API: {e}")
        
        # Fallback research data
        return await _fallback_research(topic, assistant_id)

async def _fallback_research(topic: str, assistant_id: Optional[str] = None) -> Dict[str, Any]:
    """Fallback research kdy≈æ OpenAI API nen√≠ dostupn√©"""
    logger.info(f"üîÑ Pou≈æ√≠v√°m fallback research pro t√©ma: {topic}")
    
    # Jednoduch√© kategorizov√°n√≠ t√©mat pro fallback
    if any(keyword in topic.lower() for keyword in ["AI", "umƒõl√° inteligence", "technologie", "software"]):
        research_data = {
            "key_facts": [
                "AI technologie za≈æ√≠vaj√≠ exponenci√°ln√≠ r≈Øst",
                "Trh s AI m√° hodnotu p≈ôes 100 miliard dolar≈Ø",
                "Oƒçek√°v√° se 20% roƒçn√≠ r≈Øst do roku 2030"
            ],
            "competitive_analysis": {
                "main_players": ["OpenAI", "Google", "Microsoft", "Meta"],
                "market_trends": ["Demokratizace AI", "Enterprise adoption", "Etick√© AI"]
            },
            "target_audience": {
                "primary": "Tech nad≈°enci a early adopters",
                "secondary": "Business professionals a rozhodovaƒçe",
                "demographics": "25-45 let, vysoko≈°kolsk√© vzdƒõl√°n√≠"
            },
            "content_angles": [
                "Praktick√© pou≈æit√≠ AI v byznysu",
                "Budoucnost pr√°ce s AI",
                "Etick√© aspekty AI",
                "AI tools a aplikace"
            ],
            "sources": [
                "McKinsey AI Report",
                "Gartner Technology Trends",
                "MIT Technology Review"
            ]
        }
    elif any(keyword in topic.lower() for keyword in ["marketing", "SEO", "reklama", "obsahov√Ω marketing"]):
        research_data = {
            "key_facts": [
                "Content marketing generuje 3x v√≠ce lead≈Ø ne≈æ tradiƒçn√≠ marketing",
                "SEO traffic m√° 14.6% close rate",
                "Video obsah zvy≈°uje engagement o 1200%"
            ],
            "competitive_analysis": {
                "main_players": ["HubSpot", "Semrush", "Ahrefs", "Moz"],
                "market_trends": ["AI-powered content", "Personalizace", "Voice search optimization"]
            },
            "target_audience": {
                "primary": "Market√©≈ôi a content tv≈Ørci",
                "secondary": "Business owners a agency klienti",
                "demographics": "25-40 let, marketing background"
            },
            "content_angles": [
                "ROI content marketingu",
                "Nejnovƒõj≈°√≠ SEO trendy",
                "Automatizace marketingu",
                "Mƒõ≈ôen√≠ √∫spƒõ≈°nosti kampan√≠"
            ],
            "sources": [
                "Content Marketing Institute",
                "Search Engine Journal",
                "HubSpot State of Marketing"
            ]
        }
    else:
        # Obecn√Ω fallback
        research_data = {
            "key_facts": [
                f"T√©ma '{topic}' je aktu√°lnƒõ velmi diskutovan√©",
                "Roste z√°jem o tuto oblast mezi odborn√≠ky",
                "Existuje prostor pro kvalitn√≠ content na toto t√©ma"
            ],
            "competitive_analysis": {
                "main_players": ["Zat√≠m identifikuji hlavn√≠ hr√°ƒçe"],
                "market_trends": ["Rostouc√≠ popt√°vka", "Digitalizace oboru"]
            },
            "target_audience": {
                "primary": "Lid√© se z√°jmem o " + topic,
                "secondary": "Odborn√≠ci v p≈ô√≠buzn√Ωch oblastech",
                "demographics": "≈†irok√° demografick√° skupina"
            },
            "content_angles": [
                "Z√°kladn√≠ p≈ôehled t√©matu",
                "Praktick√© tipy a rady",
                "Aktu√°ln√≠ trendy a novinky",
                "Case studies a p≈ô√≠klady"
            ],
            "sources": [
                "Odborn√© publikace",
                "Industry reports",
                "Expert interviews"
            ]
        }
    
    return {
        "research_data": research_data,
        "topic": topic,
        "research_status": "fallback",
        "assistant": "ResearchAssistant",
        "assistant_id": assistant_id,
        "timestamp": datetime.now().isoformat()
    }

# Synchronn√≠ wrapper pro zpƒõtnou kompatibilitu
def research_assistant_sync(topic: str, assistant_id: Optional[str] = None) -> Dict[str, Any]:
    """Synchronn√≠ verze pro testov√°n√≠"""
    import asyncio
    return asyncio.run(research_assistant(topic, assistant_id))

# Testovac√≠ funkce pro v√Ωvoj
if __name__ == "__main__":
    # Test p≈ô√≠klady
    test_topics = [
        "AI n√°stroje pro content marketing",
        "udr≈æiteln√° energie v ƒåR", 
        "e-commerce trendy 2025",
        "zdrav√° v√Ω≈æiva pro sportovce"
    ]
    
    for topic in test_topics:
        print(f"\n--- Research Test: {topic} ---")
        result = research_assistant_sync(topic)
        print(json.dumps(result, indent=2, ensure_ascii=False))