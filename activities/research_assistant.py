"""
ResearchAssistant - Research krok v SEO pipeline
Prov√°d√≠ online research a shroma≈æƒèuje podklady k zadan√©mu t√©matu.
"""

import json
import logging
import os
from typing import Dict, Any, Optional
from openai import OpenAI
from datetime import datetime

# Import pro datab√°zi - mus√≠me ho importovat z backend struktury
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'backend'))

from api.database import get_prisma_client

logger = logging.getLogger(__name__)

# Inicializace OpenAI klienta
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

async def research_assistant(topic: str, assistant_id: Optional[str] = None) -> Dict[str, Any]:
    """
    Prov√°d√≠ research k zadan√©mu t√©matu a shroma≈æƒèuje podklady.
    
    Args:
        topic (str): T√©ma pro research
        assistant_id (str, optional): ID asistenta pro naƒçten√≠ parametr≈Ø z DB
        
    Returns:
        Dict[str, Any]: JSON s v√Ωsledky research a shrom√°≈ædƒõn√Ωmi podklady
    """
    
    logger.info(f"üîç ResearchAssistant prov√°d√≠ research k t√©matu: {topic}")
    
    # V√Ωchoz√≠ parametry

    
    # Pokud m√°me assistant_id, naƒçteme parametry z datab√°ze
    if assistant_id:
        try:
            prisma = await get_prisma_client()
            assistant = await prisma.assistant.find_unique(where={"id": assistant_id})
            
            if assistant:
                # Pou≈æijeme parametry z datab√°ze
                params = {
                    "model": assistant.model,
                    "temperature": assistant.temperature,
                    "top_p": assistant.top_p,
                    "max_tokens": assistant.max_tokens,
                    "system_prompt": assistant.system_prompt
                }
                logger.info(f"‚úÖ Naƒçteny parametry asistenta {assistant_id}")
            else:
                raise Exception(f"‚ùå Asistent {assistant_id} nenalezen v datab√°zi! Workflow MUS√ç selhat!")
        except Exception as e:
            logger.error(f"‚ùå Chyba p≈ôi naƒç√≠t√°n√≠ parametr≈Ø asistenta: {e}")
            raise Exception(f"‚ùå Nelze naƒç√≠st asistenta {assistant_id}: {e}")
    else:
        raise Exception("‚ùå ≈Ω√ÅDN√ù assistant_id poskytnut! ResearchAssistant nem≈Ø≈æe bƒõ≈æet bez datab√°zov√© konfigurace!")
    
    # ‚úÖ POU≈Ω√çV√ÅME POUZE SYSTEM_PROMPT Z DATAB√ÅZE!
    # V≈°echny instrukce jsou v datab√°zi jako system_prompt
    user_message = f"Proveƒè research k t√©matu: {topic}"
    
    try:
        # Inicializace OpenAI client
        from utils.api_keys import get_api_key
        
        api_key = get_api_key("openai")
        if not api_key:
            logger.error("‚ùå OpenAI API kl√≠ƒç nen√≠ k dispozici")
            raise Exception("‚ùå OpenAI API kl√≠ƒç nen√≠ k dispozici pro ResearchAssistant")
            
        client = OpenAI(api_key=api_key)
        
        # Sestaven√≠ zpr√°v pro OpenAI
        messages = []
        if params["system_prompt"]:
            messages.append({"role": "system", "content": params["system_prompt"]})
        messages.append({"role": "user", "content": user_message})
        
        # Vol√°n√≠ OpenAI API
        logger.info(f"ü§ñ Vol√°m OpenAI API s modelem {params['model']}")
        response = client.chat.completions.create(
            model=params["model"],
            messages=messages,
            temperature=params["temperature"],
            top_p=params["top_p"],
            max_tokens=params["max_tokens"]
        )
        
        research_result = response.choices[0].message.content.strip()
        logger.info("‚úÖ OpenAI API √∫spƒõ≈°nƒõ vr√°tilo v√Ωsledek")
        
        # Pokus o parsov√°n√≠ JSON z odpovƒõdi
        try:
            # Pokud odpovƒõƒè obsahuje JSON block, extrahujeme ho
            if "```json" in research_result:
                json_start = research_result.find("```json") + 7
                json_end = research_result.find("```", json_start)
                if json_end != -1:
                    json_str = research_result[json_start:json_end].strip()
                    parsed_data = json.loads(json_str)
                else:
                    # Pokud nen√≠ ukonƒçovac√≠ ```, zkus√≠me cel√Ω zbytek
                    json_str = research_result[json_start:].strip()
                    parsed_data = json.loads(json_str)
            else:
                # Pokus√≠me se parsovat celou odpovƒõƒè jako JSON
                parsed_data = json.loads(research_result)
            
            return {
                "research_data": parsed_data,
                "raw_response": research_result,
                "topic": topic,
                "research_status": "success",
                "assistant": "ResearchAssistant",
                "assistant_id": assistant_id,
                "model_used": params["model"],
                "timestamp": datetime.now().isoformat()
            }
            
        except json.JSONDecodeError:
            # Pokud nelze parsovat JSON, vr√°t√≠me raw text ve struktu≈ôe
            logger.warning("‚ö†Ô∏è Nelze parsovat JSON z OpenAI odpovƒõdi")
            return {
                "research_data": {
                    "key_facts": [research_result[:500] + "..." if len(research_result) > 500 else research_result],
                    "competitive_analysis": "Detailn√≠ anal√Ωza vy≈æaduje dal≈°√≠ zpracov√°n√≠",
                    "target_audience": "Obecn√° audience z√°jemci o " + topic,
                    "content_angles": ["Z√°kladn√≠ p≈ôehled t√©matu", "Praktick√© tipy", "Aktu√°ln√≠ trendy"],
                    "sources": ["OpenAI knowledge base"]
                },
                "raw_response": research_result,
                "topic": topic,
                "research_status": "partial",
                "assistant": "ResearchAssistant",
                "assistant_id": assistant_id,
                "model_used": params["model"],
                "timestamp": datetime.now().isoformat()
            }
            
    except Exception as e:
        logger.error(f"‚ùå Chyba p≈ôi vol√°n√≠ OpenAI API: {e}")
        raise Exception(f"‚ùå ResearchAssistant selhal: {str(e)} - workflow nem≈Ø≈æe pokraƒçovat")



# Synchronn√≠ wrapper pro zpƒõtnou kompatibilitu
def research_assistant_sync(topic: str, assistant_id: Optional[str] = None) -> Dict[str, Any]:
    """Synchronn√≠ verze pro testov√°n√≠"""
    import asyncio
    return asyncio.run(research_assistant(topic, assistant_id))

# Testovac√≠ funkce pro v√Ωvoj
if __name__ == "__main__":
    # Test p≈ô√≠klady
    test_topics = [
        "AI n√°stroje pro content marketing",
        "udr≈æiteln√° energie v ƒåR", 
        "e-commerce trendy 2025",
        "zdrav√° v√Ω≈æiva pro sportovce"
    ]
    
    for topic in test_topics:
        print(f"\n--- Research Test: {topic} ---")
        result = research_assistant_sync(topic)
        print(json.dumps(result, indent=2, ensure_ascii=False))