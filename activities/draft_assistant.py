"""
DraftAssistant - Draft creation krok v SEO pipeline
VytvÃ¡Å™Ã­ prvnÃ­ draft ÄlÃ¡nku na zÃ¡kladÄ› research dat a briefu.
"""

import json
import logging
import os
from typing import Dict, Any, Optional
from openai import OpenAI
from datetime import datetime

# Import pro databÃ¡zi - musÃ­me ho importovat z backend struktury
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'backend'))

from api.database import get_prisma_client

logger = logging.getLogger(__name__)

# Inicializace OpenAI klienta
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

async def draft_assistant(input_data: Dict[str, Any], assistant_id: Optional[str] = None) -> Dict[str, Any]:
    """
    VytvÃ¡Å™Ã­ prvnÃ­ draft ÄlÃ¡nku na zÃ¡kladÄ› research dat a briefu.
    
    Args:
        input_data (Dict[str, Any]): Kombinace briefu a research dat
        assistant_id (str, optional): ID asistenta pro naÄtenÃ­ parametrÅ¯ z DB
        
    Returns:
        str: PrvnÃ­ draft ÄlÃ¡nku v HTML nebo markdown formÃ¡tu
    """
    
    logger.info(f"âœï¸ DraftAssistant vytvÃ¡Å™Ã­ draft z dat: {len(str(input_data))} znakÅ¯")
    
    # VÃ½chozÃ­ parametry - BEZ FALLBACK PROMPTU!

    
    # Pokud mÃ¡me assistant_id, naÄteme parametry z databÃ¡ze
    if assistant_id:
        try:
            prisma = await get_prisma_client()
            assistant = await prisma.assistant.find_unique(where={"id": assistant_id})
            
            if assistant:
                if not all([assistant.model, assistant.temperature is not None, assistant.top_p is not None, assistant.max_tokens, assistant.system_prompt]):
                    raise Exception(f"âŒ Asistent {assistant_id} mÃ¡ neÃºplnou konfiguraci!")
                
                params = {
                    "model": assistant.model,
                    "temperature": assistant.temperature,
                    "top_p": assistant.top_p,
                    "max_tokens": assistant.max_tokens,
                    "system_prompt": assistant.system_prompt
                }
                logger.info(f"âœ… NaÄteny parametry asistenta {assistant_id}")
            else:
                raise Exception(f"âŒ Asistent {assistant_id} nenalezen v databÃ¡zi! Workflow MUSÃ selhat!")
        except Exception as e:
            logger.error(f"âŒ Chyba pÅ™i naÄÃ­tÃ¡nÃ­ parametrÅ¯ asistenta: {e}")
            raise Exception(f"âŒ Nelze naÄÃ­st asistenta {assistant_id}: {e}")
    else:
        raise Exception("âŒ Å½ÃDNÃ assistant_id poskytnut! DraftAssistant nemÅ¯Å¾e bÄ›Å¾et bez databÃ¡zovÃ© konfigurace!")
    
    # âœ… POUÅ½ÃVÃME POUZE SYSTEM_PROMPT Z DATABÃZE!
    # VÅ¡echny instrukce jsou v databÃ¡zi jako system_prompt
    user_message = f"VytvoÅ™ ÄlÃ¡nek na zÃ¡kladÄ› tÄ›chto podkladÅ¯:\n\n{str(input_data)[:2000]}..."
    
    try:
        # Inicializace OpenAI client
        from utils.api_keys import get_api_key
        
        api_key = get_api_key("openai")
        if not api_key:
            logger.error("âŒ OpenAI API klÃ­Ä nenÃ­ k dispozici")
            raise Exception("âŒ OpenAI API klÃ­Ä nenÃ­ k dispozici pro DraftAssistant")
            
        client = OpenAI(api_key=api_key)
        
        # SestavenÃ­ zprÃ¡v pro OpenAI
        messages = []
        if params["system_prompt"]:
            messages.append({"role": "system", "content": params["system_prompt"]})
        messages.append({"role": "user", "content": user_message})
        
        # VolÃ¡nÃ­ OpenAI API
        logger.info(f"ğŸ¤– VolÃ¡m OpenAI API s modelem {params['model']}")
        response = client.chat.completions.create(
            model=params["model"],
            messages=messages,
            temperature=params["temperature"],
            top_p=params["top_p"],
            max_tokens=params["max_tokens"]
        )
        
        draft_content = response.choices[0].message.content.strip()
        logger.info(f"âœ… OpenAI API ÃºspÄ›Å¡nÄ› vytvoÅ™ilo draft: {len(draft_content)} znakÅ¯")
        
        return {"output": draft_content}
            
    except Exception as e:
        logger.error(f"âŒ Draft creation selhala: {e}")
        raise Exception(f"DraftAssistant selhal: {e}")



# SynchronnÃ­ wrapper pro zpÄ›tnou kompatibilitu
def draft_assistant_sync(input_data: Dict[str, Any], assistant_id: Optional[str] = None) -> str:
    """SynchronnÃ­ verze pro testovÃ¡nÃ­"""
    import asyncio
    return asyncio.run(draft_assistant(input_data, assistant_id))

# TestovacÃ­ funkce pro vÃ½voj
if __name__ == "__main__":
    # Test pÅ™Ã­klady
    test_data = {
        "topic": "AI nÃ¡stroje pro content marketing",
        "brief": {
            "brief": "VytvoÅ™ prÅ¯vodce AI nÃ¡stroji pro content marketing v roce 2025",
            "metadata": {
                "type": "SEO",
                "intent": "informative",
                "audience": "marketÃ©Å™i",
                "keyword_focus": "ai content marketing tools"
            }
        },
        "research_data": {
            "key_facts": [
                "AI nÃ¡stroje zvyÅ¡ujÃ­ produktivitu o 40%",
                "95% marketÃ©rÅ¯ plÃ¡nuje pouÅ¾Ã­t AI v roce 2025",
                "Content AI trh roste o 30% roÄnÄ›"
            ],
            "target_audience": {
                "primary": "MarketÃ©Å™i a content tvÅ¯rci",
                "demographics": "25-40 let, marketing background"
            },
            "content_angles": [
                "ROI AI nÃ¡strojÅ¯",
                "NejlepÅ¡Ã­ AI nÃ¡stroje 2025",
                "Implementace do workflow"
            ]
        }
    }
    
    print("\n--- Draft Creation Test ---")
    result = draft_assistant_sync(test_data)
    print(f"Draft dÃ©lka: {len(result)} znakÅ¯")
    print(result[:500] + "..." if len(result) > 500 else result)